{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SRTR Data Linkage\n",
        "\n",
        "This notebook links SRTR actual donor data to CLIF potential donors for a specified site.\n",
        "It identifies which CLIF-defined potential donors became actual organ donors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import logging\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "\n",
        "# Add parent directory to path for imports\n",
        "sys.path.append(str(Path.cwd().parent))\n",
        "from utils.io import read_data\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "from utils.config import config\n",
        "site_name = config['site_name']\n",
        "tables_path = config['tables_path']\n",
        "file_type = config['file_type']\n",
        "project_root = config['project_root']\n",
        "SRTR_data_path = config[\"SRTR_data_path\"]\n",
        "sys.path.insert(0, project_root)\n",
        "print(f\"Site Name: {site_name}\")\n",
        "print(f\"Tables Path: {tables_path}\")\n",
        "print(f\"File Type: {file_type}\")\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path(config['project_root'])\n",
        "UTILS_DIR = PROJECT_ROOT / \"utils\"\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
        "OUTPUT_FINAL_DIR = OUTPUT_DIR / \"final\"\n",
        "OUTPUT_INTERMEDIATE_DIR = OUTPUT_DIR / \"intermediate\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "donor_xlsx_path = \"../utils/unos_donors_clif.csv\"\n",
        "donor_df = pd.read_csv(donor_xlsx_path)\n",
        "\n",
        "def decode_bytes_in_object(df):\n",
        "    \"\"\"\n",
        "    Decodes byte-string values in object columns to normal strings (utf-8).\n",
        "    \"\"\"\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        try:\n",
        "            # Only decode if the whole column looks like bytes\n",
        "            if df[col].apply(lambda x: isinstance(x, bytes)).any():\n",
        "                df[col] = df[col].apply(lambda x: x.decode('utf-8', errors='replace') if isinstance(x, bytes) else x)\n",
        "        except Exception as e:\n",
        "            print(f\"Decoding error in column {col}: {e}\")\n",
        "    return df\n",
        "\n",
        "# Try ISO-8859-1 (latin1) encoding—this is more permissive than utf-8 and can handle many common SAS7BDAT byte values\n",
        "donor_deceased_filepath = SRTR_data_path + \"/\" +  \"donor_deceased.sas7bdat\"\n",
        "donor_deceased = pd.read_sas(\n",
        "    donor_deceased_filepath,\n",
        "    format='sas7bdat',\n",
        "    encoding='latin1'   # <- Changed from 'utf-8'\n",
        ")\n",
        "donor_deceased = decode_bytes_in_object(donor_deceased)\n",
        "\n",
        "institution = SRTR_data_path + \"/\" + \"institution.sas7bdat\"\n",
        "institution = pd.read_sas(\n",
        "    '/Users/kavenchhikara/Library/CloudStorage/Box-Box/SAF Q2 2025/pubsaf2506/institution.sas7bdat',\n",
        "    format='sas7bdat',\n",
        "    encoding='latin1'   # <- Changed from 'utf-8'\n",
        ")\n",
        "institution = decode_bytes_in_object(institution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify provider numbers for the current site from the hospital provider mapping\n",
        "import json\n",
        "\n",
        "hospital_mapping_path = \"../config/hospital_provider_mapping.json\"\n",
        "with open(hospital_mapping_path, \"r\") as f:\n",
        "    hospital_mapping = json.load(f)\n",
        "\n",
        "# site_name should be defined globally (e.g., \"ucmc\", \"upenn\", etc.)\n",
        "site_providers = hospital_mapping[site_name][\"provider_numbers\"]\n",
        "# Ensure all provider numbers are handled as strings for robust matching\n",
        "site_providers_str = set(str(p) for p in site_providers)\n",
        "\n",
        "# Filter donor_df rows with provider numbers for this site\n",
        "matching_donor_rows = donor_df[\n",
        "    donor_df[\"DON_HOSP_PROVIDER_NUM\"].astype(str).isin(site_providers_str)\n",
        "]\n",
        "# Extract all relevant DONOR_IDs for this site\n",
        "donor_ids_for_site = set(matching_donor_rows[\"DONOR_ID\"].astype(\"int32\"))\n",
        "\n",
        "print(f\"Site '{site_name}' provider numbers: {site_providers}\")\n",
        "print(f\"Found {len(donor_ids_for_site)} donor IDs for site '{site_name}'\")\n",
        "\n",
        "# Filter donor_deceased for DONOR_IDs in donor_ids_for_site\n",
        "donor_deceased_site = donor_deceased[\n",
        "    donor_deceased[\"DONOR_ID\"].astype(\"int32\").isin(donor_ids_for_site)\n",
        "].copy()\n",
        "\n",
        "print(f\"Filtered donor_deceased to {len(donor_deceased_site)} records for site '{site_name}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keep only the specified columns in donor_deceased_site\n",
        "donor_deceased_site_filtered = donor_deceased_site[\n",
        "    [\n",
        "        \"DONOR_ID\",\n",
        "        \"DON_OPO_CTR_ID\",\n",
        "        \"PERS_ID\",\n",
        "        \"DON_AGE\",\n",
        "        \"DON_GENDER\",\n",
        "        \"DON_RACE\",\n",
        "        \"DON_RACE_SRTR\",\n",
        "        \"DON_ETHNICITY_SRTR\",\n",
        "        \"DON_HGT_CM\",\n",
        "        \"DON_WGT_KG\",\n",
        "        \"DON_RECOV_DT\",\n",
        "        \"DON_DCD_SUPPORT_WITHDRAW_DT\",\n",
        "        \"DON_DCD_AGONAL_BEGIN_DT\",\n",
        "        \"DON_CAD_DON_COD\",\n",
        "        \"DON_DEATH_MECH\", \n",
        "        \"DON_DEATH_CIRCUM\",\n",
        "        \"DON_CREAT\",\n",
        "        \"DON_BUN\",\n",
        "        \"DON_TOT_BILI\"\n",
        "    ]\n",
        "].copy()\n",
        "\n",
        "# Save the filtered DataFrame to OUTPUT_INTERMEDIATE_DIR as a CSV\n",
        "import os\n",
        "\n",
        "output_path = os.path.join(OUTPUT_INTERMEDIATE_DIR, f\"donor_deceased_site_filtered_{site_name}.csv\")\n",
        "donor_deceased_site_filtered.to_csv(output_path, index=False)\n",
        "print(f\"Saved donor_deceased_site_filtered to {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert DON_RECOV_DT to datetime if not already\n",
        "donor_deceased_site_filtered['DON_RECOV_DT'] = pd.to_datetime(donor_deceased_site_filtered['DON_RECOV_DT'], errors='coerce')\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(donor_deceased_site_filtered['DON_RECOV_DT'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('DON_RECOV_DT')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of DON_RECOV_DT')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter donor_deceased_site_filtered to include only rows where DON_RECOV_DT is between 2018 and 2024\n",
        "donor_deceased_site_filtered = donor_deceased_site_filtered[\n",
        "    (donor_deceased_site_filtered['DON_RECOV_DT'] >= '2018-01-01') &\n",
        "    (donor_deceased_site_filtered['DON_RECOV_DT'] < '2024-01-01')\n",
        "].copy()\n",
        "print(f\"Filtered donor_deceased_site_filtered to dates between 2018 and 2024. New shape: {donor_deceased_site_filtered.shape}\")\n",
        "\n",
        "# Print number of unique donors in the filtered dataframe\n",
        "num_unique_donors = donor_deceased_site_filtered['DONOR_ID'].nunique()\n",
        "print(f\"Number of unique donors in filtered data: {num_unique_donors}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Link with CLIF data for potential donors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "# Read the Parquet file 'final_cohort_df.parquet' from OUTPUT_INTERMEDIATE_DIR\n",
        "final_cohort_path = os.path.join(OUTPUT_INTERMEDIATE_DIR, \"final_cohort_df.parquet\")\n",
        "final_cohort_df = pd.read_parquet(final_cohort_path)\n",
        "print(f\"Read final_cohort_df from {final_cohort_path} with shape {final_cohort_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_cohort_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Utility to report variable stats in consistent format\n",
        "def print_var_summary(df, col, name, is_numeric=True, fmt=\"{:.1f}\", extra=None):\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Data type: {df[col].dtype}\")\n",
        "    missing = df[col].isna().sum()\n",
        "    miss_pct = df[col].isna().mean() * 100\n",
        "    print(f\"  Missing values: {missing} ({miss_pct:.1f}%)\")\n",
        "    if is_numeric and df[col].notna().any():\n",
        "        _min = df[col].min()\n",
        "        _max = df[col].max()\n",
        "        _mean = df[col].mean()\n",
        "        _std = df[col].std()\n",
        "        print(f\"  Range: {fmt.format(_min)} to {fmt.format(_max)}\")\n",
        "        print(f\"  Mean (SD): {fmt.format(_mean)} ({fmt.format(_std)})\")\n",
        "        if extra == \"quantiles\":\n",
        "            qtls = df[col].quantile([0.25, 0.5, 0.75]).values\n",
        "            print(f\"  Quartiles: {np.round(qtls, 2)}\")\n",
        "    elif not is_numeric:\n",
        "        uniques = df[col].unique()\n",
        "        print(f\"  Unique values: {uniques}\")\n",
        "        print(f\"  Value counts:\")\n",
        "        print(df[col].value_counts())\n",
        "    print()\n",
        "\n",
        "def analyze_matching_variables(clif_df, srtr_df):\n",
        "    \"\"\"Analyze and compare key variables between CLIF and SRTR dataframes.\"\"\"\n",
        "\n",
        "    def sep(title, section=None):\n",
        "        print(\"=\"*80)\n",
        "        if title: print(title.upper())\n",
        "        if section: print(\"=\"*80 + f\"\\n{section}\")\n",
        "\n",
        "    sep(\"Dataframe overview\")\n",
        "    print(f\"CLIF Records: {len(clif_df):,}\")\n",
        "    print(f\"SRTR Records: {len(srtr_df):,}\\n\")\n",
        "\n",
        "    # 1. DATE VARIABLES\n",
        "    sep(None, \"1. DATE VARIABLES\")\n",
        "    print_var_summary(clif_df, 'final_death_dttm', \"CLIF - final_death_dttm\", is_numeric=False)\n",
        "    print_var_summary(srtr_df, 'DON_RECOV_DT', \"SRTR - DON_RECOV_DT\", is_numeric=False)\n",
        "    # Special handling for DCD if present\n",
        "    if 'DON_DCD_SUPPORT_WITHDRAW_DT' in srtr_df.columns:\n",
        "        print(\"SRTR - DON_DCD_SUPPORT_WITHDRAW_DT (DCD only):\")\n",
        "        col = 'DON_DCD_SUPPORT_WITHDRAW_DT'\n",
        "        print(f\"  Non-null values: {srtr_df[col].notna().sum()}\")\n",
        "        print(f\"  Date range: {srtr_df[col].min()} to {srtr_df[col].max()}\\n\")\n",
        "\n",
        "    # 2. AGE\n",
        "    sep(None, \"2. AGE\")\n",
        "    print_var_summary(clif_df, 'age_at_death', \"CLIF - age_at_death\", is_numeric=True, fmt=\"{:.1f}\", extra=\"quantiles\")\n",
        "    print_var_summary(srtr_df, 'DON_AGE', \"SRTR - DON_AGE\", is_numeric=True, fmt=\"{:.1f}\", extra=\"quantiles\")\n",
        "\n",
        "    # 3. SEX/GENDER\n",
        "    sep(None, \"3. SEX/GENDER\")\n",
        "    print_var_summary(clif_df, 'sex_category', \"CLIF - sex_category\", is_numeric=False)\n",
        "    print_var_summary(srtr_df, 'DON_GENDER', \"SRTR - DON_GENDER\", is_numeric=False)\n",
        "\n",
        "    # 4. RACE\n",
        "    sep(None, \"4. RACE\")\n",
        "    print(\"CLIF - race_category:\")\n",
        "    print(f\"  Data type: {clif_df['race_category'].dtype}\")\n",
        "    uniq = clif_df['race_category'].nunique()\n",
        "    print(f\"  Unique values ({uniq} total):\")\n",
        "    print(clif_df['race_category'].value_counts().head(10))\n",
        "    print()\n",
        "    print(\"SRTR - DON_RACE_SRTR:\")\n",
        "    print(f\"  Data type: {srtr_df['DON_RACE_SRTR'].dtype}\")\n",
        "    uniq_srtr = srtr_df['DON_RACE_SRTR'].nunique()\n",
        "    print(f\"  Unique values ({uniq_srtr} total):\")\n",
        "    print(srtr_df['DON_RACE_SRTR'].value_counts().head(10))\n",
        "    print()\n",
        "\n",
        "    # 5. ETHNICITY\n",
        "    sep(None, \"5. ETHNICITY\")\n",
        "    print(\"CLIF - ethnicity_category:\")\n",
        "    print(f\"  Data type: {clif_df['ethnicity_category'].dtype}\")\n",
        "    print(\"  Unique values:\")\n",
        "    print(clif_df['ethnicity_category'].value_counts())\n",
        "    print()\n",
        "    print(\"SRTR - DON_ETHNICITY_SRTR:\")\n",
        "    print(f\"  Data type: {srtr_df['DON_ETHNICITY_SRTR'].dtype}\")\n",
        "    print(\"  Unique values:\")\n",
        "    print(srtr_df['DON_ETHNICITY_SRTR'].value_counts())\n",
        "    print()\n",
        "\n",
        "    # 6. HEIGHT\n",
        "    sep(None, \"6. HEIGHT (cm)\")\n",
        "    print_var_summary(clif_df, 'last_height_cm', \"CLIF - last_height_cm\", is_numeric=True, fmt=\"{:.1f}\")\n",
        "    print_var_summary(srtr_df, 'DON_HGT_CM', \"SRTR - DON_HGT_CM\", is_numeric=True, fmt=\"{:.1f}\")\n",
        "\n",
        "    # 7. WEIGHT\n",
        "    sep(None, \"7. WEIGHT (kg)\")\n",
        "    print_var_summary(clif_df, 'last_weight_kg', \"CLIF - last_weight_kg\", is_numeric=True, fmt=\"{:.1f}\")\n",
        "    print_var_summary(srtr_df, 'DON_WGT_KG', \"SRTR - DON_WGT_KG\", is_numeric=True, fmt=\"{:.1f}\")\n",
        "\n",
        "    # 8. CREATININE\n",
        "    sep(None, \"8. CREATININE\")\n",
        "    print_var_summary(clif_df, 'creatinine_value', \"CLIF - creatinine_value\", is_numeric=True, fmt=\"{:.2f}\")\n",
        "    print_var_summary(srtr_df, 'DON_CREAT', \"SRTR - DON_CREAT\", is_numeric=True, fmt=\"{:.2f}\")\n",
        "\n",
        "    # 9. BILIRUBIN\n",
        "    sep(None, \"9. BILIRUBIN\")\n",
        "    print_var_summary(clif_df, 'bilirubin_total_value', \"CLIF - bilirubin_total_value\", is_numeric=True, fmt=\"{:.2f}\")\n",
        "    print_var_summary(srtr_df, 'DON_TOT_BILI', \"SRTR - DON_TOT_BILI\", is_numeric=True, fmt=\"{:.2f}\")\n",
        "\n",
        "# Run the analysis\n",
        "analyze_matching_variables(final_cohort_df, donor_deceased_site_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def standardize_dataframes_for_matching(clif_df, srtr_df):\n",
        "    \"\"\"\n",
        "    Standardize CLIF and SRTR dataframes for matching\n",
        "    \"\"\"\n",
        "\n",
        "    # Create copies to avoid modifying originals\n",
        "    clif_std = clif_df.copy()\n",
        "    srtr_std = srtr_df.copy()\n",
        "\n",
        "    print(\"Standardizing dataframes for matching...\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # 1. STANDARDIZE DATES\n",
        "    # ----------------------------------------\n",
        "    print(\"1. Standardizing dates...\")\n",
        "\n",
        "    # Convert CLIF death date to date only (no time) for matching\n",
        "    clif_std['death_date'] = pd.to_datetime(clif_std['final_death_dttm']).dt.date\n",
        "\n",
        "    # Convert SRTR recovery date to date only\n",
        "    srtr_std['recovery_date'] = pd.to_datetime(srtr_std['DON_RECOV_DT']).dt.date\n",
        "\n",
        "    # For DCD donors, we might want to use withdraw date as closer to death\n",
        "    if 'DON_DCD_SUPPORT_WITHDRAW_DT' in srtr_std.columns:\n",
        "        srtr_std['dcd_withdraw_date'] = pd.to_datetime(srtr_std['DON_DCD_SUPPORT_WITHDRAW_DT']).dt.date\n",
        "        # Use withdraw date if available, otherwise recovery date\n",
        "        srtr_std['match_date'] = srtr_std['dcd_withdraw_date'].fillna(srtr_std['recovery_date'])\n",
        "    else:\n",
        "        srtr_std['match_date'] = srtr_std['recovery_date']\n",
        "\n",
        "    print(f\"  CLIF death dates: {clif_std['death_date'].min()} to {clif_std['death_date'].max()}\")\n",
        "    print(f\"  SRTR match dates: {srtr_std['match_date'].min()} to {srtr_std['match_date'].max()}\")\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # 2. STANDARDIZE SEX/GENDER\n",
        "    # ----------------------------------------\n",
        "    print(\"\\n2. Standardizing sex/gender...\")\n",
        "\n",
        "    # Map CLIF sex to M/F\n",
        "    sex_map_clif = {'Male': 'M', 'Female': 'F'}\n",
        "    clif_std['sex_std'] = clif_std['sex_category'].map(sex_map_clif)\n",
        "\n",
        "    # SRTR already uses M/F\n",
        "    srtr_std['sex_std'] = srtr_std['DON_GENDER']\n",
        "\n",
        "    print(f\"  CLIF sex values: {clif_std['sex_std'].value_counts().to_dict()}\")\n",
        "    print(f\"  SRTR sex values: {srtr_std['sex_std'].value_counts().to_dict()}\")\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # 3. STANDARDIZE RACE\n",
        "    # ----------------------------------------\n",
        "    print(\"\\n3. Standardizing race...\")\n",
        "\n",
        "    # Create race mapping\n",
        "    race_map_clif = {\n",
        "        'Black or African American': 'BLACK',\n",
        "        'White': 'WHITE',\n",
        "        'Asian': 'ASIAN',\n",
        "        'American Indian or Alaska Native': 'NATIVE',\n",
        "        'Native Hawaiian or Other Pacific Islander': 'PACIFIC',\n",
        "        'Other': 'OTHER',\n",
        "        'Unknown': 'UNKNOWN'\n",
        "    }\n",
        "\n",
        "    clif_std['race_std'] = clif_std['race_category'].map(race_map_clif).fillna('UNKNOWN')\n",
        "    srtr_std['race_std'] = srtr_std['DON_RACE_SRTR'].fillna('UNKNOWN')\n",
        "\n",
        "    print(\"  CLIF race categories:\")\n",
        "    print(clif_std['race_std'].value_counts().head())\n",
        "    print(\"  SRTR race categories:\")\n",
        "    print(srtr_std['race_std'].value_counts().head())\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # 4. STANDARDIZE ETHNICITY\n",
        "    # ----------------------------------------\n",
        "    print(\"\\n4. Standardizing ethnicity...\")\n",
        "\n",
        "    ethnicity_map_clif = {\n",
        "        'Hispanic': 'HISPANIC',\n",
        "        'Non-Hispanic': 'NON-HISPANIC',\n",
        "        'Unknown': 'UNKNOWN'\n",
        "    }\n",
        "\n",
        "    ethnicity_map_srtr = {\n",
        "        'LATINO': 'HISPANIC',\n",
        "        'NLATIN': 'NON-HISPANIC'\n",
        "    }\n",
        "\n",
        "    clif_std['ethnicity_std'] = clif_std['ethnicity_category'].map(ethnicity_map_clif).fillna('UNKNOWN')\n",
        "    srtr_std['ethnicity_std'] = srtr_std['DON_ETHNICITY_SRTR'].map(ethnicity_map_srtr).fillna('UNKNOWN')\n",
        "\n",
        "    print(f\"  CLIF ethnicity: {clif_std['ethnicity_std'].value_counts().to_dict()}\")\n",
        "    print(f\"  SRTR ethnicity: {srtr_std['ethnicity_std'].value_counts().to_dict()}\")\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # 5. STANDARDIZE AGE\n",
        "    # ----------------------------------------\n",
        "    print(\"\\n5. Standardizing age...\")\n",
        "\n",
        "    clif_std['age_std'] = clif_std['age_at_death'].round().astype('Int64')\n",
        "    srtr_std['age_std'] = srtr_std['DON_AGE'].round().astype('Int64')\n",
        "\n",
        "    print(\n",
        "        f\"  CLIF age: mean={clif_std['age_std'].mean():.1f}, \"\n",
        "        f\"range={clif_std['age_std'].min()}-{clif_std['age_std'].max()}\"\n",
        "    )\n",
        "    print(\n",
        "        f\"  SRTR age: mean={srtr_std['age_std'].mean():.1f}, \"\n",
        "        f\"range={srtr_std['age_std'].min()}-{srtr_std['age_std'].max()}\"\n",
        "    )\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # 6. STANDARDIZE CLINICAL VALUES\n",
        "    # ----------------------------------------\n",
        "    print(\"\\n6. Standardizing clinical values...\")\n",
        "\n",
        "    # Height (cm) - round to integers\n",
        "    clif_std['height_std'] = clif_std['last_height_cm'].round().astype('Int64')\n",
        "    srtr_std['height_std'] = srtr_std['DON_HGT_CM'].round().astype('Int64')\n",
        "\n",
        "    # Weight (kg) - round to 1 decimal\n",
        "    clif_std['weight_std'] = clif_std['last_weight_kg'].round(1)\n",
        "    srtr_std['weight_std'] = srtr_std['DON_WGT_KG'].round(1)\n",
        "\n",
        "    # Creatinine - round to 2 decimals\n",
        "    clif_std['creatinine_std'] = clif_std['creatinine_value'].round(2)\n",
        "    srtr_std['creatinine_std'] = srtr_std['DON_CREAT'].round(2)\n",
        "\n",
        "    # Bilirubin - round to 2 decimals\n",
        "    clif_std['bilirubin_std'] = clif_std['bilirubin_total_value'].round(2)\n",
        "    srtr_std['bilirubin_std'] = srtr_std['DON_TOT_BILI'].round(2)\n",
        "\n",
        "    print(f\"  Height missing - CLIF: {clif_std['height_std'].isna().sum()}, SRTR: {srtr_std['height_std'].isna().sum()}\")\n",
        "    print(f\"  Weight missing - CLIF: {clif_std['weight_std'].isna().sum()}, SRTR: {srtr_std['weight_std'].isna().sum()}\")\n",
        "    print(f\"  Creatinine missing - CLIF: {clif_std['creatinine_std'].isna().sum()}, SRTR: {srtr_std['creatinine_std'].isna().sum()}\")\n",
        "    print(f\"  Bilirubin missing - CLIF: {clif_std['bilirubin_std'].isna().sum()}, SRTR: {srtr_std['bilirubin_std'].isna().sum()}\")\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # 7. ADD IDENTIFIERS\n",
        "    # ----------------------------------------\n",
        "    print(\"\\n7. Adding standardized identifiers...\")\n",
        "\n",
        "    clif_std['clif_id'] = clif_std['patient_id']\n",
        "    srtr_std['srtr_donor_id'] = srtr_std['DONOR_ID']\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Standardization complete!\")\n",
        "\n",
        "    # Return standardized columns\n",
        "    clif_columns = [\n",
        "        'clif_id', 'death_date', 'age_std', 'sex_std', 'race_std',\n",
        "        'ethnicity_std', 'height_std', 'weight_std', 'creatinine_std', 'bilirubin_std'\n",
        "    ]\n",
        "    srtr_columns = [\n",
        "        'srtr_donor_id', 'match_date', 'age_std', 'sex_std', 'race_std',\n",
        "        'ethnicity_std', 'height_std', 'weight_std', 'creatinine_std',\n",
        "        'bilirubin_std', 'DON_DEATH_MECH', 'DON_CAD_DON_COD'\n",
        "    ]\n",
        "\n",
        "    return clif_std[clif_columns], srtr_std[srtr_columns]\n",
        "\n",
        "# Standardize the dataframes\n",
        "clif_standardized, srtr_standardized = standardize_dataframes_for_matching(\n",
        "    final_cohort_df,\n",
        "    donor_deceased_site_filtered\n",
        ")\n",
        "\n",
        "# Display summaries\n",
        "print(\"\\nCLIF Standardized (first 5 rows):\")\n",
        "print(clif_standardized.head())\n",
        "print(f\"\\nShape: {clif_standardized.shape}\")\n",
        "\n",
        "print(\"\\nSRTR Standardized (first 5 rows):\")\n",
        "print(srtr_standardized.head())\n",
        "print(f\"\\nShape: {srtr_standardized.shape}\")\n",
        "\n",
        "# Now, let's create a matching function that accounts for the small number of SRTR records and the date range differences:\n",
        "\n",
        "def perform_matching(clif_std, srtr_std, date_window_days=7, age_tolerance=2):\n",
        "    \"\"\"\n",
        "    Perform matching between CLIF and SRTR standardized dataframes\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    clif_std : DataFrame\n",
        "        Standardized CLIF data\n",
        "    srtr_std : DataFrame\n",
        "        Standardized SRTR data\n",
        "    date_window_days : int\n",
        "        Number of days before/after death to consider a match\n",
        "    age_tolerance : int\n",
        "        Age difference tolerance in years\n",
        "    \"\"\"\n",
        "\n",
        "    matches = []\n",
        "\n",
        "    print(f\"Matching {len(clif_std)} CLIF records against {len(srtr_std)} SRTR records...\")\n",
        "    print(f\"Date window: ±{date_window_days} days\")\n",
        "    print(f\"Age tolerance: ±{age_tolerance} years\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for _, srtr_row in srtr_std.iterrows():\n",
        "        # Filter CLIF records by basic demographics\n",
        "        potential_matches = clif_std[\n",
        "            (clif_std['sex_std'] == srtr_row['sex_std']) &\n",
        "            (abs(clif_std['age_std'] - srtr_row['age_std']) <= age_tolerance)\n",
        "        ].copy()\n",
        "\n",
        "        if len(potential_matches) == 0:\n",
        "            continue\n",
        "\n",
        "        # Calculate date difference\n",
        "        potential_matches['date_diff'] = (\n",
        "            potential_matches['death_date'] - srtr_row['match_date']\n",
        "        ).apply(lambda x: x.days if pd.notna(x) else 999)\n",
        "\n",
        "        # Filter by date window\n",
        "        potential_matches = potential_matches[\n",
        "            abs(potential_matches['date_diff']) <= date_window_days\n",
        "        ]\n",
        "\n",
        "        if len(potential_matches) == 0:\n",
        "            continue\n",
        "\n",
        "        # Calculate match score\n",
        "        for _, clif_row in potential_matches.iterrows():\n",
        "            match_score = 0\n",
        "            match_details = []\n",
        "\n",
        "            # Exact matches get higher scores\n",
        "            if clif_row['race_std'] == srtr_row['race_std']:\n",
        "                match_score += 10\n",
        "                match_details.append('race')\n",
        "\n",
        "            if clif_row['ethnicity_std'] == srtr_row['ethnicity_std']:\n",
        "                match_score += 5\n",
        "                match_details.append('ethnicity')\n",
        "\n",
        "            # Clinical value matches (if not missing)\n",
        "            if pd.notna(clif_row['height_std']) and pd.notna(srtr_row['height_std']):\n",
        "                if abs(clif_row['height_std'] - srtr_row['height_std']) <= 5:\n",
        "                    match_score += 3\n",
        "                    match_details.append('height')\n",
        "\n",
        "            if pd.notna(clif_row['weight_std']) and pd.notna(srtr_row['weight_std']):\n",
        "                if abs(clif_row['weight_std'] - srtr_row['weight_std']) <= 5:\n",
        "                    match_score += 3\n",
        "                    match_details.append('weight')\n",
        "\n",
        "            if pd.notna(clif_row['creatinine_std']) and pd.notna(srtr_row['creatinine_std']):\n",
        "                if abs(clif_row['creatinine_std'] - srtr_row['creatinine_std']) <= 0.5:\n",
        "                    match_score += 2\n",
        "                    match_details.append('creatinine')\n",
        "\n",
        "            # Store match\n",
        "            matches.append({\n",
        "                'clif_id': clif_row['clif_id'],\n",
        "                'srtr_donor_id': srtr_row['srtr_donor_id'],\n",
        "                'date_diff_days': clif_row['date_diff'],\n",
        "                'age_diff': abs(clif_row['age_std'] - srtr_row['age_std']),\n",
        "                'match_score': match_score,\n",
        "                'match_details': ', '.join(match_details),\n",
        "                'clif_death_date': clif_row['death_date'],\n",
        "                'srtr_match_date': srtr_row['match_date']\n",
        "            })\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    matches_df = pd.DataFrame(matches)\n",
        "\n",
        "    if len(matches_df) > 0:\n",
        "        # Sort by match score\n",
        "        matches_df = matches_df.sort_values('match_score', ascending=False)\n",
        "\n",
        "        # Remove duplicates (keep best match for each CLIF patient)\n",
        "        matches_df = matches_df.drop_duplicates(subset=['clif_id'], keep='first')\n",
        "\n",
        "        print(f\"\\nFound {len(matches_df)} potential matches\")\n",
        "        print(\"Match score distribution:\")\n",
        "        print(matches_df['match_score'].value_counts().sort_index(ascending=False))\n",
        "    else:\n",
        "        print(\"No matches found!\")\n",
        "\n",
        "    return matches_df\n",
        "\n",
        "# Perform matching\n",
        "matches = perform_matching(clif_standardized, srtr_standardized, date_window_days=7, age_tolerance=2)\n",
        "\n",
        "if len(matches) > 0:\n",
        "    print(\"\\nTop 10 matches by score:\")\n",
        "    print(matches.head(10)[['clif_id', 'srtr_donor_id', 'date_diff_days', 'match_score', 'match_details']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "date_window_days = 7\n",
        "age_tolerance = 1\n",
        "\n",
        "print(f\"Matching {len(clif_standardized)} CLIF records against {len(srtr_standardized)} SRTR records...\")\n",
        "print(f\"Date window: ±{date_window_days} days\")\n",
        "print(f\"Age tolerance: ±{age_tolerance} years\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Copy data\n",
        "clif_std = clif_standardized.copy()\n",
        "srtr_std = srtr_standardized.copy()\n",
        "\n",
        "# Do cartesian join\n",
        "clif_std['_tmpkey'] = 1\n",
        "srtr_std['_tmpkey'] = 1\n",
        "merged = pd.merge(clif_std, srtr_std, on='_tmpkey', suffixes=('_clif', '_srtr')).drop('_tmpkey', axis=1)\n",
        "\n",
        "# Ensure dates are datetime\n",
        "merged['death_date'] = pd.to_datetime(merged['death_date'], errors='coerce')\n",
        "merged['match_date'] = pd.to_datetime(merged['match_date'], errors='coerce')\n",
        "\n",
        "# Calculate absolute date difference\n",
        "merged['date_diff_days'] = (merged['death_date'] - merged['match_date']).dt.days\n",
        "\n",
        "# Filter for:\n",
        "# - death date window\n",
        "# - age tolerance\n",
        "# - exact race match\n",
        "# - exact ethnicity match\n",
        "mask = (\n",
        "    merged['date_diff_days'].notnull() &\n",
        "    (np.abs(merged['date_diff_days']) <= date_window_days) &\n",
        "    (np.abs(merged['age_std_clif'] - merged['age_std_srtr']) <= age_tolerance) &\n",
        "    (merged['race_std_clif'] == merged['race_std_srtr']) &\n",
        "    (merged['ethnicity_std_clif'] == merged['ethnicity_std_srtr'])\n",
        ")\n",
        "\n",
        "matches = merged[mask].copy()\n",
        "\n",
        "if len(matches) == 0:\n",
        "    print(\"No matches found with exact match criteria (death date window, age, race, ethnicity)\")\n",
        "else:\n",
        "    matches['age_diff'] = np.abs(matches['age_std_clif'] - matches['age_std_srtr'])\n",
        "    matches = (matches\n",
        "        .loc[:, [\n",
        "            'clif_id', 'srtr_donor_id', 'date_diff_days', 'age_diff',\n",
        "            'death_date', 'match_date', 'race_std_clif', 'ethnicity_std_clif'\n",
        "        ]]\n",
        "        .rename(columns={\n",
        "            'death_date': 'clif_death_date',\n",
        "            'match_date': 'srtr_match_date',\n",
        "            'race_std_clif': 'race',\n",
        "            'ethnicity_std_clif': 'ethnicity'\n",
        "        })\n",
        "    )\n",
        "    print(f\"\\nFound {len(matches)} exact matches.\")\n",
        "    print(\"\\nTop 10 matches:\")\n",
        "    print(matches.head(10)[[\n",
        "        'clif_id', 'srtr_donor_id', 'date_diff_days', 'age_diff', 'race', 'ethnicity'\n",
        "    ]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 1. APPEND MATCH RESULTS TO FINAL_COHORT_DF\n",
        "# ============================================\n",
        "\n",
        "# Copy the final cohort dataframe for enhancement\n",
        "final_cohort_df_enhanced = final_cohort_df.copy()\n",
        "\n",
        "# Generate a set of matched patient IDs\n",
        "matched_patient_ids = set(matches['clif_id'].unique())\n",
        "\n",
        "# Add a boolean flag indicating actual donors\n",
        "final_cohort_df_enhanced['actual_donor'] = final_cohort_df_enhanced['patient_id'].isin(matched_patient_ids)\n",
        "\n",
        "# Prepare the matches dataframe for merging by renaming 'clif_id' to 'patient_id'\n",
        "matches_for_merge = matches[['clif_id', 'srtr_donor_id', 'date_diff_days']].rename(\n",
        "    columns={'clif_id': 'patient_id'}\n",
        ")\n",
        "\n",
        "# Merge SRTR donor information into final_cohort_df_enhanced\n",
        "final_cohort_df_enhanced = final_cohort_df_enhanced.merge(\n",
        "    matches_for_merge,\n",
        "    on='patient_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Print summary statistics in a standardized format\n",
        "print(\"=\" * 80)\n",
        "print(\"ENHANCED COHORT SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total patients: {len(final_cohort_df_enhanced):,}\")\n",
        "print(f\"Actual donors (matched to SRTR): {final_cohort_df_enhanced['actual_donor'].sum():,}\")\n",
        "print(f\"CALC eligible: {final_cohort_df_enhanced['calc_flag'].sum():,}\")\n",
        "print(f\"CLIF eligible: {final_cohort_df_enhanced['clif_eligible_donors'].sum():,}\")\n",
        "print(\n",
        "    f\"Either CALC or CLIF eligible: \"\n",
        "    f\"{((final_cohort_df_enhanced['calc_flag']) | (final_cohort_df_enhanced['clif_eligible_donors'])).sum():,}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CONCENTRIC CIRCLES WITH ACTUAL DONORS\n",
        "# ============================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "import numpy as np\n",
        "\n",
        "def create_concentric_circles_with_actual_donors(final_cohort_df_enhanced, output_path=None):\n",
        "    \"\"\"\n",
        "    Create side-by-side concentric circle diagrams showing potential → actual donors.\n",
        "    Uses the same format as cohort_visualizations.py but adds actual donors.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    final_cohort_df_enhanced : pandas.DataFrame\n",
        "        Enhanced dataframe with 'actual_donor' flag.\n",
        "    output_path : str, optional\n",
        "        Path to save the generated figure.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    matplotlib.figure.Figure\n",
        "        The generated matplotlib Figure object.\n",
        "    \"\"\"\n",
        "    # Setup figure and axes\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    # Numbers for both definitions\n",
        "    calc_potential = final_cohort_df_enhanced['calc_flag'].sum()\n",
        "    calc_actual = final_cohort_df_enhanced.loc[final_cohort_df_enhanced['calc_flag'], 'actual_donor'].sum()\n",
        "\n",
        "    clif_potential = final_cohort_df_enhanced['clif_eligible_donors'].sum()\n",
        "    clif_actual = final_cohort_df_enhanced.loc[final_cohort_df_enhanced['clif_eligible_donors'], 'actual_donor'].sum()\n",
        "\n",
        "    details = [\n",
        "        {\n",
        "            \"ax\": axes[0],\n",
        "            \"definition\": \"CALC\",\n",
        "            \"subplot_label\": \"(A)\",\n",
        "            \"potential_n\": calc_potential,\n",
        "            \"actual_n\": calc_actual\n",
        "        },\n",
        "        {\n",
        "            \"ax\": axes[1],\n",
        "            \"definition\": \"CLIF\",\n",
        "            \"subplot_label\": \"(B)\",\n",
        "            \"potential_n\": clif_potential,\n",
        "            \"actual_n\": clif_actual\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for d in details:\n",
        "        ax = d[\"ax\"]\n",
        "        definition = d[\"definition\"]\n",
        "        subplot_label = d[\"subplot_label\"]\n",
        "        potential_n = d[\"potential_n\"]\n",
        "        actual_n = d[\"actual_n\"]\n",
        "\n",
        "        ax.set_xlim(-1.5, 1.5)\n",
        "        ax.set_ylim(-1.5, 1.5)\n",
        "        ax.set_aspect('equal')\n",
        "        ax.axis('off')\n",
        "\n",
        "        if definition == \"CALC\":\n",
        "            stage1_n = len(final_cohort_df_enhanced)\n",
        "            stage2_n = final_cohort_df_enhanced['age_75_less'].sum()\n",
        "            stage3_n = final_cohort_df_enhanced.loc[\n",
        "                final_cohort_df_enhanced['age_75_less'] &\n",
        "                (final_cohort_df_enhanced['icd10_ischemic'] |\n",
        "                 final_cohort_df_enhanced['icd10_cerebro'] |\n",
        "                 final_cohort_df_enhanced['icd10_external'])\n",
        "            ].shape[0]\n",
        "            stage4_n = potential_n\n",
        "            steps = [\n",
        "                {'n': stage1_n, 'label': 'All inpatient deaths', 'stage': 1},\n",
        "                {'n': stage2_n, 'label': 'Age ≤75', 'stage': 2},\n",
        "                {'n': stage3_n, 'label': 'Cause', 'stage': 3},\n",
        "                {'n': stage4_n, 'label': 'No contraindications', 'stage': 4},\n",
        "                {'n': actual_n, 'label': 'Actual donors', 'stage': 5}\n",
        "            ]\n",
        "            colors_map = {\n",
        "                1: ('#D3D3D3', 'none'),\n",
        "                2: ('#000000', 'none'),\n",
        "                3: ('#2196F3', 'none'),\n",
        "                4: ('#ADD8E6', '#ADD8E6'),\n",
        "                5: ('#4CAF50', '#4CAF50')\n",
        "            }\n",
        "        else:\n",
        "            stage1_n = len(final_cohort_df_enhanced)\n",
        "            stage2_n = final_cohort_df_enhanced['age_75_less'].sum()\n",
        "            stage3_n = final_cohort_df_enhanced.loc[\n",
        "                final_cohort_df_enhanced['age_75_less'] &\n",
        "                final_cohort_df_enhanced['imv_48hr_expire']\n",
        "            ].shape[0]\n",
        "            stage4_n = final_cohort_df_enhanced.loc[\n",
        "                final_cohort_df_enhanced['age_75_less'] &\n",
        "                final_cohort_df_enhanced['imv_48hr_expire'] &\n",
        "                final_cohort_df_enhanced['no_positive_culture_48hrs'] &\n",
        "                (~final_cohort_df_enhanced['icd10_contraindication'])\n",
        "            ].shape[0]\n",
        "            stage5_n = potential_n\n",
        "            steps = [\n",
        "                {'n': stage1_n, 'label': 'All inpatient deaths', 'stage': 1},\n",
        "                {'n': stage2_n, 'label': 'Age ≤75', 'stage': 2},\n",
        "                {'n': stage3_n, 'label': 'IMV within 48h', 'stage': 3},\n",
        "                {'n': stage4_n, 'label': 'No contraindications', 'stage': 4},\n",
        "                {'n': stage5_n, 'label': 'Pass organ quality', 'stage': 5},\n",
        "                {'n': actual_n, 'label': 'Actual donors', 'stage': 6}\n",
        "            ]\n",
        "            colors_map = {\n",
        "                1: ('#D3D3D3', 'none'),\n",
        "                2: ('#000000', 'none'),\n",
        "                3: ('#9C27B0', 'none'),\n",
        "                4: ('#F44336', 'none'),\n",
        "                5: ('#ADD8E6', '#ADD8E6'),\n",
        "                6: ('#4CAF50', '#4CAF50')\n",
        "            }\n",
        "\n",
        "        initial_n = steps[0]['n']\n",
        "        max_radius = 1.0  # always = sqrt(initial_n / initial_n) = 1\n",
        "\n",
        "        base_center_x = -0.3\n",
        "        center_y = 0\n",
        "\n",
        "        for i in range(len(steps)-1, -1, -1):\n",
        "            step = steps[i]\n",
        "            stage_num = step['stage']\n",
        "            curr_n = step['n']\n",
        "            radius = 1.0 * np.sqrt(curr_n / initial_n) if curr_n > 0 else 0\n",
        "            edge_color, face_color = colors_map.get(stage_num, ('#808080', 'none'))\n",
        "            indent_amount = 0.6 * (1 - radius / max_radius) if max_radius > 0 else 0\n",
        "            center_x = base_center_x + indent_amount\n",
        "\n",
        "            if definition == 'CALC':\n",
        "                fill = stage_num >= 4\n",
        "            else:\n",
        "                fill = stage_num >= 5\n",
        "\n",
        "            alpha = 0.7 if fill else 1.0\n",
        "\n",
        "            circle = Circle((center_x, center_y), radius,\n",
        "                facecolor=face_color if fill else 'none',\n",
        "                edgecolor=edge_color,\n",
        "                linewidth=2.5,\n",
        "                alpha=alpha,\n",
        "                fill=fill\n",
        "            )\n",
        "            ax.add_patch(circle)\n",
        "\n",
        "            # Annotate numbers\n",
        "            if step == steps[-1]:  # Actual donors\n",
        "                if actual_n > 0:\n",
        "                    percentage = (actual_n / potential_n * 100) if potential_n > 0 else 0\n",
        "                    ax.text(center_x, center_y,\n",
        "                        f\"{actual_n}\\n({percentage:.1f}%)\",\n",
        "                        ha='center', va='center', fontsize=10, fontweight='bold', color='white'\n",
        "                    )\n",
        "            elif step == steps[-2]:  # Potential donors\n",
        "                if actual_n > 0 and potential_n > 0:\n",
        "                    potential_radius = radius\n",
        "                    actual_radius = 1.0 * np.sqrt(actual_n / initial_n)\n",
        "                    ring_radius = (potential_radius + actual_radius) / 2\n",
        "                    text_y = center_y + ring_radius * 0.7\n",
        "                else:\n",
        "                    text_y = center_y\n",
        "                ax.text(center_x, text_y,\n",
        "                    f\"{potential_n}\",\n",
        "                    ha='center', va='center', fontsize=11, fontweight='bold', color='#333'\n",
        "                )\n",
        "\n",
        "        title = f\"{subplot_label} {definition} Definition\"\n",
        "        ax.text(base_center_x, 1.35, title, ha='center', va='center',\n",
        "                fontsize=12, fontweight='bold')\n",
        "\n",
        "        # Removed conversion rate from the definition title and below the title\n",
        "\n",
        "    # LEGEND\n",
        "    legend_labels = []\n",
        "    legend_handles = []\n",
        "\n",
        "    legend_entries = [\n",
        "        ('All inpatient hospital deaths', '#D3D3D3'),\n",
        "        ('Patients aged ≤75 at death', '#000000'),\n",
        "        ('Cause consistent with donation (CALC)', '#2196F3'),\n",
        "        ('IMV within 48hrs (CLIF)', '#9C27B0'),\n",
        "        ('No contraindications', '#F44336'),\n",
        "        ('Pass organ quality assessment (CLIF)', '#ADD8E6'),\n",
        "    ]\n",
        "\n",
        "    for label, color in legend_entries:\n",
        "        if color == '#ADD8E6':\n",
        "            legend_handles.append(plt.Line2D([0], [0], marker='o', color='w',\n",
        "                                             markerfacecolor=color, markersize=10, linestyle='None'))\n",
        "        else:\n",
        "            legend_handles.append(plt.Line2D([0], [0], color=color, linewidth=3))\n",
        "        legend_labels.append(label)\n",
        "\n",
        "    # Actual donors\n",
        "    legend_handles.append(plt.Line2D([0], [0], marker='o', color='w',\n",
        "                                     markerfacecolor='#4CAF50', markersize=10, linestyle='None'))\n",
        "    legend_labels.append('Actual donors (matched to SRTR)')\n",
        "\n",
        "    fig.legend(legend_handles, legend_labels, loc='lower center', ncol=4, frameon=True, fontsize=8, bbox_to_anchor=(0.5, -0.02))\n",
        "\n",
        "    plt.suptitle('Potential vs Actual Deceased Organ Donors', fontsize=16, fontweight='bold', y=0.98)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if output_path:\n",
        "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Circles with actual donors saved to: {output_path}\")\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Generate the figure\n",
        "fig = create_concentric_circles_with_actual_donors(\n",
        "    final_cohort_df_enhanced,\n",
        "    output_path='circles_potential_vs_actual.png'\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"POTENTIAL VS ACTUAL DONORS SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "calc_potential = final_cohort_df_enhanced['calc_flag'].sum()\n",
        "calc_actual = final_cohort_df_enhanced.loc[final_cohort_df_enhanced['calc_flag'], 'actual_donor'].sum()\n",
        "calc_rate = (calc_actual / calc_potential * 100) if calc_potential > 0 else 0\n",
        "\n",
        "clif_potential = final_cohort_df_enhanced['clif_eligible_donors'].sum()\n",
        "clif_actual = final_cohort_df_enhanced.loc[final_cohort_df_enhanced['clif_eligible_donors'], 'actual_donor'].sum()\n",
        "clif_rate = (clif_actual / clif_potential * 100) if clif_potential > 0 else 0\n",
        "\n",
        "print(f\"\\nCALC Definition:\")\n",
        "print(f\"  Potential donors: {calc_potential:,}\")\n",
        "print(f\"  Actual donors: {calc_actual:,}\")\n",
        "\n",
        "print(f\"\\nCLIF Definition:\")\n",
        "print(f\"  Potential donors: {clif_potential:,}\")\n",
        "print(f\"  Actual donors: {clif_actual:,}\")\n",
        "\n",
        "\n",
        "either_potential = (final_cohort_df_enhanced['calc_flag'] | final_cohort_df_enhanced['clif_eligible_donors']).sum()\n",
        "either_actual = final_cohort_df_enhanced.loc[\n",
        "    (final_cohort_df_enhanced['calc_flag'] | final_cohort_df_enhanced['clif_eligible_donors']),\n",
        "    'actual_donor'\n",
        "].sum()\n",
        "either_rate = (either_actual / either_potential * 100) if either_potential > 0 else 0\n",
        "\n",
        "print(f\"\\nEither CALC or CLIF:\")\n",
        "print(f\"  Potential donors: {either_potential:,}\")\n",
        "print(f\"  Actual donors: {either_actual:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# INVESTIGATE NON-ELIGIBLE ACTUAL DONORS\n",
        "# ============================================\n",
        "\n",
        "# Identify the actual donors who were NOT eligible by either criteria\n",
        "actual_donors = final_cohort_df_enhanced[final_cohort_df_enhanced['actual_donor'] == True]\n",
        "non_eligible_donors = actual_donors[\n",
        "    (actual_donors['calc_flag'] == False) &\n",
        "    (actual_donors['clif_eligible_donors'] == False)\n",
        "]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ANALYSIS: ACTUAL DONORS NOT CAPTURED BY CALC OR CLIF CRITERIA\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nTotal matched actual donors: {len(actual_donors)}\")\n",
        "print(f\"Not eligible by either criteria: {len(non_eligible_donors)} \"\n",
        "      f\"({len(non_eligible_donors)/len(actual_donors)*100:.1f}%)\")\n",
        "\n",
        "# Analyze why they weren't eligible\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"WHY WERE ACTUAL DONORS EXCLUDED?\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check age criteria\n",
        "over_75 = non_eligible_donors['age_75_less'] == False\n",
        "n_over_75 = over_75.sum()\n",
        "n_non_eligible = len(non_eligible_donors)\n",
        "print(f\"\\n1. AGE > 75 years: {n_over_75} donors \"\n",
        "      f\"({n_over_75/n_non_eligible*100:.1f}%)\")\n",
        "if n_over_75 > 0:\n",
        "    ages = non_eligible_donors.loc[over_75, 'age_at_death']\n",
        "    print(f\"   Age range: {ages.min():.1f} - {ages.max():.1f}\")\n",
        "    print(f\"   Mean age: {ages.mean():.1f} (SD: {ages.std():.1f})\")\n",
        "\n",
        "# For those ≤75, check other criteria\n",
        "under_75_donors = non_eligible_donors[non_eligible_donors['age_75_less'] == True]\n",
        "n_under_75 = len(under_75_donors)\n",
        "print(f\"\\n2. For donors ≤75 years (n={n_under_75}):\")\n",
        "\n",
        "if n_under_75 > 0:\n",
        "    # CALC criteria failures\n",
        "    print(\"\\n   CALC Criteria Failures:\")\n",
        "\n",
        "    # Check cause of death\n",
        "    has_qualifying_cause = (\n",
        "        (under_75_donors['icd10_ischemic'] == True) |\n",
        "        (under_75_donors['icd10_cerebro'] == True) |\n",
        "        (under_75_donors['icd10_external'] == True)\n",
        "    )\n",
        "    no_qualifying_cause = ~has_qualifying_cause\n",
        "    print(f\"   - No qualifying cause of death: {no_qualifying_cause.sum()}\")\n",
        "\n",
        "    # Check contraindications\n",
        "    has_contraindication = under_75_donors['icd10_contraindication'] == True\n",
        "    print(f\"   - Has contraindication: {has_contraindication.sum()}\")\n",
        "\n",
        "    # CLIF criteria failures\n",
        "    print(\"\\n   CLIF Criteria Failures:\")\n",
        "\n",
        "    # Check IMV\n",
        "    no_imv = under_75_donors['imv_48hr_expire'] == False\n",
        "    print(f\"   - No IMV within 48hrs: {no_imv.sum()}\")\n",
        "\n",
        "    # For those with IMV, check other criteria\n",
        "    with_imv = under_75_donors[under_75_donors['imv_48hr_expire'] == True]\n",
        "    if len(with_imv) > 0:\n",
        "        print(f\"   - With IMV but failed other criteria: {len(with_imv)}\")\n",
        "        positive_culture = with_imv['no_positive_culture_48hrs'] == False\n",
        "        print(f\"     • Positive culture: {positive_culture.sum()}\")\n",
        "        has_contra = with_imv['icd10_contraindication'] == True\n",
        "        print(f\"     • Has contraindication: {has_contra.sum()}\")\n",
        "        organ_fail = with_imv['organ_check_pass'] == False\n",
        "        print(f\"     • Failed organ quality: {organ_fail.sum()}\")\n",
        "\n",
        "# Create detailed breakdown table\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DETAILED BREAKDOWN OF ALL ACTUAL DONORS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "breakdown_data = {\n",
        "    'Category': [\n",
        "        'CALC eligible only',\n",
        "        'CLIF eligible only',\n",
        "        'Both CALC & CLIF eligible',\n",
        "        'Neither (Age > 75)',\n",
        "        'Neither (Age ≤ 75, other reasons)',\n",
        "        'Total actual donors'\n",
        "    ],\n",
        "    'N': [\n",
        "        len(actual_donors[(actual_donors['calc_flag'] == True) &\n",
        "                          (actual_donors['clif_eligible_donors'] == False)]),\n",
        "        len(actual_donors[(actual_donors['calc_flag'] == False) &\n",
        "                          (actual_donors['clif_eligible_donors'] == True)]),\n",
        "        len(actual_donors[(actual_donors['calc_flag'] == True) &\n",
        "                          (actual_donors['clif_eligible_donors'] == True)]),\n",
        "        len(non_eligible_donors[non_eligible_donors['age_75_less'] == False]),\n",
        "        len(non_eligible_donors[non_eligible_donors['age_75_less'] == True]),\n",
        "        len(actual_donors)\n",
        "    ]\n",
        "}\n",
        "\n",
        "breakdown_df = pd.DataFrame(breakdown_data)\n",
        "breakdown_df['Percentage'] = (breakdown_df['N'] / len(actual_donors) * 100).round(1)\n",
        "print(breakdown_df.to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
