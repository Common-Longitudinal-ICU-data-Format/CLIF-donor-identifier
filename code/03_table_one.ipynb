{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53fe813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import polars as pl \n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, project_root)\n",
    "from utils.config import config\n",
    "from utils.io import read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort_df = pl.read_parquet(\"../output/intermediate/relevant_cohort_with_deathage.parquet\")\n",
    "cohort_df = pl.read_parquet(\"../output/intermediate/calc_final_df_with_desc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18433aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name = config['site_name']\n",
    "tables_path = config['tables_path']\n",
    "file_type = config['file_type']\n",
    "\n",
    "adt_filepath = f\"{tables_path}/clif_adt.{file_type}\"\n",
    "hospitalization_filepath = f\"{tables_path}/clif_hospitalization.{file_type}\"\n",
    "patient_filepath = f\"{tables_path}/clif_patient.{file_type}\"\n",
    "hospital_dx_filepath = f\"{tables_path}/clif_hospital_diagnosis.{file_type}\"\n",
    "labs_filepath = f\"{tables_path}/clif_labs.{file_type}\"\n",
    "patient_assess_filepath = f\"{tables_path}/clif_patient_assessments.{file_type}\"\n",
    "respiratory_filepath = f\"{tables_path}/clif_respiratory_support.{file_type}\"\n",
    "\n",
    "adt_df = read_data(adt_filepath, file_type)\n",
    "hospitalization_df = read_data(hospitalization_filepath, file_type)\n",
    "patient_df = read_data(patient_filepath, file_type)\n",
    "hospital_dx_df = read_data(hospital_dx_filepath, file_type)\n",
    "labs_df = read_data(labs_filepath, file_type)\n",
    "pat_assess_df = read_data(patient_assess_filepath, file_type)\n",
    "resp_df = read_data(respiratory_filepath, file_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first ICU dttm for ICU encounters, Calculate ICU LOS and Hospital LOS for each encounter in days. \n",
    "# ==============================================================================\n",
    "adt_cohort = cohort_df.join(adt_df, on = \"hospitalization_id\", how = \"left\")\n",
    "\n",
    "hosp_admission_summary = (\n",
    "    adt_cohort\n",
    "    .group_by('encounter_block')\n",
    "    .agg([\n",
    "        pl.col('in_dttm').min().alias('min_in_dttm'),\n",
    "        pl.col('out_dttm').max().alias('max_out_dttm'),\n",
    "        pl.col('location_category').first().alias('first_admission_location')\n",
    "    ])\n",
    ")\n",
    "hosp_admission_summary = hosp_admission_summary.with_columns(\n",
    "    (\n",
    "        (pl.col('max_out_dttm') - pl.col('min_in_dttm')).dt.total_days().alias('hospital_length_of_stay_days')\n",
    "    )\n",
    ")\n",
    "\n",
    "# lowercase the column in polars\n",
    "adt_cohort = adt_cohort.with_columns(\n",
    "    pl.col(\"location_category\").str.to_lowercase()\n",
    ")\n",
    "\n",
    "# restrict to ICU rows\n",
    "icu_df = adt_cohort.filter(pl.col('location_category') == \"icu\")\n",
    "\n",
    "# find first ICU in time per 'encounter_block'\n",
    "first_in = (\n",
    "    icu_df\n",
    "    .group_by('encounter_block')\n",
    "    .agg(\n",
    "        pl.col('in_dttm').min().alias('first_icu_in_dttm')\n",
    "    )\n",
    ")\n",
    "\n",
    "# join to get the matching 'out_dttm'\n",
    "icu_summary = (\n",
    "    first_in.join(\n",
    "        icu_df.select(['hospitalization_id', 'in_dttm', 'out_dttm', 'encounter_block']),\n",
    "        left_on=['encounter_block', 'first_icu_in_dttm'],\n",
    "        right_on=['encounter_block', 'in_dttm'],\n",
    "        how='left',\n",
    "    )\n",
    "    .rename({'out_dttm': 'first_icu_out_dttm'})\n",
    ")\n",
    "\n",
    "# compute LOS in days (out - in)\n",
    "icu_summary = icu_summary.with_columns(\n",
    "    (\n",
    "        (pl.col('first_icu_out_dttm') - pl.col('first_icu_in_dttm'))\n",
    "        .dt.total_days()\n",
    "        .alias('first_icu_los_days')\n",
    "    )\n",
    ")\n",
    "\n",
    "# trim to just the columns needed\n",
    "icu_summary = icu_summary.select([\n",
    "    'encounter_block', 'first_icu_in_dttm', 'first_icu_out_dttm', 'first_icu_los_days'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to get first_recorded_dttm for each encounter_block for those on imv\n",
    "imv_df = resp_df.filter(pl.col(\"device_category\") == \"IMV\")\n",
    "imv_cohort = cohort_df.join(imv_df, on = \"hospitalization_id\", how = \"left\")\n",
    "first_recorded_dttm = (\n",
    "    imv_cohort\n",
    "    .group_by(\"encounter_block\")\n",
    "    .agg(\n",
    "        pl.col(\"recorded_dttm\").min().alias(\"first_recorded_dttm\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Filter labs_df for target categories\n",
    "target_lab_order_categories = [\"blood_gas\", \"cbc\"]\n",
    "labs_cohort = cohort_df.join(labs_df, on = \"hospitalization_id\", how = \"left\")\n",
    "labs_of_interest = labs_cohort.filter(\n",
    "    pl.col(\"lab_order_category\").is_in(target_lab_order_categories))\n",
    "\n",
    "# Join labs to first_recorded_dttm by encounter_block\n",
    "labs_with_first = labs_of_interest.join(\n",
    "    first_recorded_dttm, on=\"encounter_block\", how=\"inner\"\n",
    ")\n",
    "labs_with_first\n",
    "\n",
    "# Only keep rows where labs were collected within 24 hrs after first_recorded_dttm\n",
    "timeframe = 24\n",
    "labs_within_timeframe = labs_with_first.filter(\n",
    "    (pl.col(\"lab_collect_dttm\") >= pl.col(\"first_recorded_dttm\")) &\n",
    "    (pl.col(\"lab_collect_dttm\") < (pl.col(\"first_recorded_dttm\") + pl.duration(hours=timeframe)))\n",
    ").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9025d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_interest = [\"gcs_total\", \"RASS\"]\n",
    "assessments_cohort = cohort_df.join(pat_assess_df, on = \"hospitalization_id\", how = \"left\")\n",
    "assessments_of_interest = assessments_cohort.filter(\n",
    "    pl.col(\"assessment_category\").is_in(assessment_interest)).unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df_1 = cohort_df.join(patient_df, on='patient_id', how='left')\n",
    "cohort_df_2 = cohort_df_1.join(\n",
    "    hospitalization_df,\n",
    "    on=['patient_id', 'hospitalization_id'],\n",
    "    how='left',\n",
    "    suffix=\"_hosp\"\n",
    ")\n",
    "cohort_df_3 = cohort_df_2.join(\n",
    "    hospital_dx_df,\n",
    "    on=['hospitalization_id'],\n",
    "    how='left',\n",
    "    suffix=\"_dx\"\n",
    ")\n",
    "cohort_df_4 = cohort_df_3.join(\n",
    "    labs_within_timeframe,\n",
    "    on=['patient_id', 'hospitalization_id', 'encounter_block'],\n",
    "    how='left',\n",
    "    suffix=\"_labs\"\n",
    ")\n",
    "cohort_df_5 = (\n",
    "    cohort_df_4\n",
    "    .join(icu_summary, on='encounter_block', how='left', suffix=\"_icu\")\n",
    "    .join(hosp_admission_summary, on='encounter_block', how='left', suffix=\"_hadm\")\n",
    ")\n",
    "cohort_df_6 = cohort_df_5.with_columns(\n",
    "    pl.col('first_admission_location').fill_null('Missing')\n",
    ")\n",
    "\n",
    "final_tableone_df = cohort_df_6.select([\n",
    "    'patient_id', 'hospitalization_id', 'encounter_block', 'admission_dttm',\n",
    "    'discharge_dttm', 'age_at_admission', 'age_at_death', 'discharge_category', 'first_admission_location', 'admission_type_category',\n",
    "    'race_category', 'ethnicity_category', 'sex_category', 'language_category', 'first_icu_los_days', 'hospital_length_of_stay_days',\n",
    "    'diagnosis_code', 'diagnosis_code_format', 'diagnosis_primary', 'poa_present', 'lab_category', 'lab_value_numeric'\n",
    "]).unique()\n",
    "final_tableone_df = final_tableone_df.with_columns(\n",
    "    pl.col('admission_dttm').dt.year().alias('admission_year')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b44836",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = final_tableone_df['encounter_block'].is_duplicated().sum()\n",
    "print(f\"Duplicate encounter_blocks: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"Multiple rows per encounter_block found. Keeping last value...\")\n",
    "    # pl.DataFrame.unique(keep='last') drops duplicate rows, keeping the last occurrence\n",
    "    tableone_df = final_tableone_df.unique(subset=['encounter_block'], keep='last')\n",
    "else:\n",
    "    tableone_df = final_tableone_df\n",
    "\n",
    "print(f\"Final tableone_df shape: {tableone_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_cohort = tableone_df.select(['patient_id', 'race_category', 'ethnicity_category', 'sex_category', 'age_at_admission']).unique(subset=['patient_id'])\n",
    "print(f\"Unique patients: {len(patient_cohort):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ICD-10 descriptions - CORRECTED VERSION\n",
    "def load_icd_descriptions(filepath):\n",
    "    \"\"\"\n",
    "    Load ICD-10 codes and descriptions from text file.\n",
    "    Format: CODE    DESCRIPTION (separated by whitespace)\n",
    "    Returns: dict mapping code (no dots) to description\n",
    "    \"\"\"\n",
    "    icd_dict = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # Split by whitespace: first part is code, rest is description\n",
    "            parts = line.split(None, 1)  # Split on whitespace, max 2 parts\n",
    "            if len(parts) >= 2:\n",
    "                code = parts[0].strip()\n",
    "                description = parts[1].strip()\n",
    "                icd_dict[code] = description\n",
    "    return icd_dict\n",
    "\n",
    "# Helper function to clean ICD codes (remove dots)\n",
    "def clean_icd_code(code):\n",
    "    \"\"\"Remove dots from ICD codes for matching\"\"\"\n",
    "    if code is None:\n",
    "        return None\n",
    "    return str(code).replace(\".\", \"\")\n",
    "\n",
    "# Load the ICD descriptions\n",
    "icd_descriptions = load_icd_descriptions(\"../icd10orderfiles/icd10cm_codes_2026.txt\")\n",
    "print(f\"Loaded {len(icd_descriptions):,} ICD-10 code descriptions\")\n",
    "\n",
    "# Test\n",
    "test_code = \"A41.9\"\n",
    "clean_test = clean_icd_code(test_code)\n",
    "print(f\"Test: {test_code} -> {clean_test} -> {icd_descriptions.get(clean_test, 'Not found')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Table One for Patient Assessments (e.g., for assessments_of_interest)\n",
    "def make_table_one_patient_assessments(df, value_col=\"numerical_value\", category_col=\"assessment_category\"):\n",
    "    \"\"\"\n",
    "    Summary table for patient assessments by category.\n",
    "    For each assessment_category:\n",
    "      - N\n",
    "      - median [Q1, Q3] of assessment_value\n",
    "    \"\"\"\n",
    "    # Aggregate stats per assessment_category\n",
    "    grouped = (\n",
    "        df\n",
    "        .filter(pl.col(category_col).is_not_null() & pl.col(value_col).is_not_null())\n",
    "        .group_by(category_col, maintain_order=True)\n",
    "        .agg([\n",
    "            pl.count().alias(\"n\"),\n",
    "            pl.col(value_col).median().alias(\"median\"),\n",
    "            pl.col(value_col).quantile(0.25).alias(\"q1\"),\n",
    "            pl.col(value_col).quantile(0.75).alias(\"q3\"),\n",
    "        ])\n",
    "        .sort(\"n\", descending=True)\n",
    "    )\n",
    "    # Build table: one row for N, one for median/q1/q3 for each category\n",
    "    rows = []\n",
    "    for cat, n, median, q1, q3 in grouped.rows():\n",
    "        cat_str = str(cat)\n",
    "        rows.append((f\"N: {cat_str}\", f\"{n:,}\"))\n",
    "        rows.append((f\"  {cat_str} value, median [Q1, Q3]\", f\"{median:.1f} [{q1:.1f}, {q3:.1f}]\"))\n",
    "    return pl.DataFrame({\"Variable\": [r[0] for r in rows], \"Overall\": [r[1] for r in rows]})\n",
    "\n",
    "# Example usage for patient assessments:\n",
    "\n",
    "tbl_patient_assessments = make_table_one_patient_assessments(assessments_of_interest)\n",
    "\n",
    "# You can concatenate this with the main table one as needed, e.g.:\n",
    "# tbl_final = pl.concat([tbl_overall, tbl_patient_assessments], how=\"vertical\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_patient_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892007f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_table_one_optimized(df, patient_demographics, id_col='encounter_block'):\n",
    "    \"\"\"\n",
    "    Optimized Table One generation - pre-computes values, minimizes iterations.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    N_enc = df.height\n",
    "    N_pat = patient_demographics.height\n",
    "    N_hospitals = df['hospital_id'].n_unique() if \"hospital_id\" in df.columns else None\n",
    "\n",
    "\n",
    "    continuous_stats = {}\n",
    "    for col in ['age_at_admission', 'age_at_death', 'first_icu_los_days', 'hospital_length_of_stay_days']:\n",
    "        if col in df.columns:\n",
    "            data = (\n",
    "                patient_demographics[col].drop_nulls()\n",
    "                if col == 'age_at_admission'\n",
    "                else df[col].drop_nulls()\n",
    "            )\n",
    "            if data.len() > 0:\n",
    "                continuous_stats[col] = {\n",
    "                    'median': data.median(),\n",
    "                    'q1': data.quantile(0.25),\n",
    "                    'q3': data.quantile(0.75)\n",
    "                }\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1. Size\n",
    "    # -------------------------------------------------------------------------\n",
    "    rows.append((\"N: Encounter blocks\", f\"{N_enc:,}\"))\n",
    "    rows.append((\"N: Unique patients\", f\"{N_pat:,}\"))\n",
    "    if N_hospitals is not None:\n",
    "        rows.append((\"N: Hospitals\", f\"{N_hospitals:,}\"))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2. Demographics\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Age\n",
    "    if 'age_at_admission' in continuous_stats:\n",
    "        s = continuous_stats['age_at_admission']\n",
    "        rows.append((\n",
    "            \"Age at admission, median [Q1, Q3]\",\n",
    "            f\"{s['median']:.0f} [{s['q1']:.0f}, {s['q3']:.0f}]\"\n",
    "        ))\n",
    "    # Add age_at_death statistics\n",
    "    if 'age_at_death' in continuous_stats:\n",
    "        s = continuous_stats['age_at_death']\n",
    "        rows.append((\n",
    "            \"Age at death, median [Q1, Q3]\",\n",
    "            f\"{s['median']:.0f} [{s['q1']:.0f}, {s['q3']:.0f}]\"\n",
    "        ))\n",
    "\n",
    "    # Fast categorical stats in Polars\n",
    "    def cat_n_pct_fast(data, col, title, denominator):\n",
    "        value_counts_df = data.select([\n",
    "            pl.col(col)\n",
    "        ]).with_columns(\n",
    "            pl.col(col).alias(\"level\")\n",
    "        ).group_by(\"level\", maintain_order=True).len().rename(\n",
    "            {\"len\": \"count\"}\n",
    "        ).sort(\"count\", descending=True)\n",
    "        for row in value_counts_df.rows():\n",
    "            lvl, cnt = row\n",
    "            pct = 100 * cnt / denominator\n",
    "            lvl_str = str(lvl) if (lvl is not None and not (isinstance(lvl, float) and lvl != lvl)) else \"Missing\"\n",
    "            rows.append((f\"  {title}: {lvl_str}\", f\"{cnt:,} ({pct:.1f}%)\"))\n",
    "\n",
    "    cat_n_pct_fast(patient_demographics, 'race_category', 'Race', N_pat)\n",
    "    cat_n_pct_fast(patient_demographics, 'ethnicity_category', 'Ethnicity', N_pat)\n",
    "    cat_n_pct_fast(patient_demographics, 'sex_category', 'Sex', N_pat)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3. Diagnoses (Primary and Secondary)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Primary Diagnosis (diagnosis_primary==1), top 5\n",
    "    if \"diagnosis_code\" in df.columns and \"diagnosis_primary\" in df.columns:\n",
    "        primary_dx = (\n",
    "            df.filter(pl.col(\"diagnosis_primary\") == 1)\n",
    "              .group_by(\"diagnosis_code\", maintain_order=True)\n",
    "              .len()\n",
    "              .sort(\"len\", descending=True)\n",
    "        )\n",
    "        total_primary = primary_dx[\"len\"].sum() if primary_dx.height > 0 else 0\n",
    "        if hasattr(total_primary, 'item'):\n",
    "            total_primary = total_primary.item()\n",
    "        else:\n",
    "            total_primary = int(total_primary)\n",
    "        if primary_dx.height > 0:\n",
    "            rows.append((\"Top 5 primary diagnoses\", \"\"))\n",
    "            for i, row_ in enumerate(primary_dx.rows()):\n",
    "                if i >= 5:\n",
    "                    break\n",
    "                dx_code, dx_cnt = row_\n",
    "                pct = 100 * dx_cnt / max(1, total_primary)\n",
    "                clean_code = clean_icd_code(dx_code)\n",
    "                desc = icd_descriptions.get(clean_code, \"Description not found\")\n",
    "                rows.append((f\"  PrimDx #{i+1}: {dx_code} - {desc}\", f\"{dx_cnt:,} ({pct:.1f}%)\"))\n",
    "        else:\n",
    "            rows.append((\"Top 5 primary diagnoses\", \"N/A\"))\n",
    "\n",
    "        # Secondary Diagnoses (diagnosis_primary==0), top 5\n",
    "        secondary_dx = (\n",
    "            df.filter(pl.col(\"diagnosis_primary\") == 0)\n",
    "              .group_by(\"diagnosis_code\", maintain_order=True)\n",
    "              .len()\n",
    "              .sort(\"len\", descending=True)\n",
    "        )\n",
    "        # Only if there are secondary diagnoses\n",
    "        total_sec = secondary_dx[\"len\"].sum() if secondary_dx.height > 0 else 0\n",
    "        if hasattr(total_sec, 'item'):\n",
    "            total_sec = total_sec.item()\n",
    "        else:\n",
    "            total_sec = int(total_sec)\n",
    "        if secondary_dx.height > 0:\n",
    "            rows.append((\"Top 5 secondary diagnoses\", \"\"))\n",
    "            for i, row_ in enumerate(secondary_dx.rows()):\n",
    "                if i >= 5:\n",
    "                    break\n",
    "                dx_code, dx_cnt = row_\n",
    "                pct = 100 * dx_cnt / max(1, total_sec)\n",
    "                clean_code = clean_icd_code(dx_code)\n",
    "                desc = icd_descriptions.get(clean_code, \"Description not found\")\n",
    "                rows.append((f\"  SecDx #{i+1}: {dx_code} - {desc}\", f\"{dx_cnt:,} ({pct:.1f}%)\"))\n",
    "        else:\n",
    "            rows.append((\"Top 5 secondary diagnoses\", \"N/A\"))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4. Admission and Location\n",
    "    # -------------------------------------------------------------------------\n",
    "    cat_n_pct_fast(df, 'first_admission_location', 'First admission location', N_enc)\n",
    "    if 'admission_type_category' in df.columns:\n",
    "        cat_n_pct_fast(df, 'admission_type_category', 'Admission type', N_enc)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5. Length of Stay (use pre-computed stats)\n",
    "    # -------------------------------------------------------------------------\n",
    "    for col, label in [\n",
    "        ('first_icu_los_days', 'ICU length of stay (days)'),\n",
    "        ('hospital_length_of_stay_days', 'Hospital length of stay (days)')\n",
    "    ]:\n",
    "        if col in continuous_stats:\n",
    "            s = continuous_stats[col]\n",
    "            rows.append((\n",
    "                f\"{label}, median [Q1, Q3]\",\n",
    "                f\"{s['median']:.1f} [{s['q1']:.1f}, {s['q3']:.1f}]\"\n",
    "            ))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6. Labs within specified time frame (per lab category)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Use lab_category and lab_value_numeric from df\n",
    "    if 'lab_category' in df.columns and 'lab_value_numeric' in df.columns:\n",
    "        lab_cat = \"lab_category\"\n",
    "        # Get only numeric values\n",
    "        lab_stats = (\n",
    "            df\n",
    "            .filter(pl.col(lab_cat).is_not_null() & pl.col(\"lab_value_numeric\").is_not_null())\n",
    "            .group_by(lab_cat)\n",
    "            .agg([\n",
    "                pl.count().alias(\"n\"),\n",
    "                pl.col(\"lab_value_numeric\").median().alias(\"median\"),\n",
    "                pl.col(\"lab_value_numeric\").quantile(0.25, \"nearest\").alias(\"q1\"),\n",
    "                pl.col(\"lab_value_numeric\").quantile(0.75, \"nearest\").alias(\"q3\")\n",
    "            ])\n",
    "            .sort(\"n\", descending=True)\n",
    "        )\n",
    "\n",
    "        if lab_stats.height > 0:\n",
    "            rows.append((f\"Lab values within {timeframe} of IMV\", \"\"))\n",
    "            for i, row in enumerate(lab_stats.rows()):\n",
    "                cat, n, median, q1, q3 = row\n",
    "                rows.append((f\"  {cat}: count\", f\"{n:,}\"))\n",
    "                rows.append((f\"  {cat}: median [Q1, Q3]\", f\"{median:.1f} [{q1:.1f}, {q3:.1f}]\"))\n",
    "        else:\n",
    "            rows.append((f\"Lab values within {timeframe} of IMV\", \"N/A\"))\n",
    "    else:\n",
    "        rows.append((f\"Lab values within {timeframe} of IMV\", \"N/A\"))\n",
    "\n",
    "\n",
    "    # Assemble Polars DataFrame\n",
    "    return pl.DataFrame({\"Variable\": [r[0] for r in rows], \"Overall\": [r[1] for r in rows]})\n",
    "\n",
    "\n",
    "\n",
    "# Generate overall table\n",
    "tbl_overall = make_table_one_optimized(tableone_df, patient_cohort)\n",
    "tbl_final = pl.concat([tbl_overall, tbl_patient_assessments], how=\"vertical\")\n",
    "\n",
    "# print(tbl_overall.write_csv(separator='|'))  # POLARS always includes header when writing to a string\n",
    "# print(tbl_overall)\n",
    "\n",
    "# # Save\n",
    "tbl_final.write_csv(\"../output/final/table_one_overall_calc.csv\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#Generate by Year (Optimized, POLARS)\n",
    "# ============================================================================\n",
    "\n",
    "if 'admission_year' in tableone_df.columns:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING TABLE ONE BY YEAR (OPTIMIZED)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Get unique years once, sort once\n",
    "    years = sorted([y for y in tableone_df['admission_year'].unique().to_list() if y is not None])\n",
    "    print(f\"Years found: {years}\")\n",
    "\n",
    "    var_order = tbl_overall[\"Variable\"].to_list()\n",
    "    results = {\"Overall\": tbl_overall.with_columns(\n",
    "        pl.col(\"Variable\"), pl.col(\"Overall\")\n",
    "    ).to_dict(as_series=False)[\"Overall\"]}\n",
    "\n",
    "    # Group once, iterate over years\n",
    "    for yr in years:\n",
    "        # Filter data for that year\n",
    "        df_year = tableone_df.filter(pl.col(\"admission_year\") == yr)\n",
    "        pat_year = patient_cohort.filter(pl.col('patient_id').is_in(df_year['patient_id'].implode()))\n",
    "\n",
    "        # Generate table for this year\n",
    "        tbl_year = make_table_one_optimized(df_year, pat_year)\n",
    "        # Map by variable for reindexing\n",
    "        yr_map = dict(zip(tbl_year[\"Variable\"].to_list(), tbl_year[\"Overall\"].to_list()))\n",
    "        results[str(int(yr))] = [yr_map.get(v, \"\") for v in var_order]\n",
    "    \n",
    "    # Assemble a wide Polars DataFrame  \n",
    "    table_by_year = pl.DataFrame(\n",
    "        {\"Variable\": var_order, **{k: v for k, v in results.items()}}\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    # table_by_year.write_csv(\"../output/final/table_one_by_year.csv\")\n",
    "    # print(\"Saved: ../output/final/table_one_by_year.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925415e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gcs & rass \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
