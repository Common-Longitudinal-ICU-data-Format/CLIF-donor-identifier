{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3505a026",
   "metadata": {},
   "source": [
    "# Potential Organ Donor Identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df99155",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d800d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import polars as pl \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from utils.config import config\n",
    "from utils.io import read_data\n",
    "from utils.strobe_diagram import create_consort_diagram\n",
    "from clifpy.utils.stitching_encounters import stitch_encounters\n",
    "from utils.outlier_handler import apply_outlier_handling\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name = config['site_name']\n",
    "tables_path = config['tables_path']\n",
    "file_type = config['file_type']\n",
    "project_root = config['project_root']\n",
    "sys.path.insert(0, project_root)\n",
    "print(f\"Site Name: {site_name}\")\n",
    "print(f\"Tables Path: {tables_path}\")\n",
    "print(f\"File Type: {file_type}\")\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path(config['project_root'])\n",
    "UTILS_DIR = PROJECT_ROOT / \"utils\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "OUTPUT_FINAL_DIR = OUTPUT_DIR / \"final\"\n",
    "OUTPUT_INTERMEDIATE_DIR = OUTPUT_DIR / \"intermediate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481add3",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1bf5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read required tables\n",
    "adt_filepath = f\"{tables_path}/clif_adt.{file_type}\"\n",
    "hospitalization_filepath = f\"{tables_path}/clif_hospitalization.{file_type}\"\n",
    "patient_filepath = f\"{tables_path}/clif_patient.{file_type}\"\n",
    "adt_df = read_data(adt_filepath, file_type)\n",
    "hospitalization_df = read_data(hospitalization_filepath, file_type)\n",
    "patient_df = read_data(patient_filepath, file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5aa4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_patients = patient_df[\"patient_id\"].n_unique()\n",
    "strobe_counts[\"0_all_patients\"] = total_patients\n",
    "strobe_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574ff44",
   "metadata": {},
   "source": [
    "# Identify decedents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_decedents_df = hospitalization_df.filter(\n",
    "    pl.col('discharge_category').str.to_lowercase() == 'expired'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_decedent_patient_ids = all_decedents_df.select('patient_id').to_series().to_list()\n",
    "all_decedent_hosp_ids = all_decedents_df.select('hospitalization_id').to_series().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be8d84",
   "metadata": {},
   "source": [
    "# Stitch Encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if hospitalization_df has duplicate patient_id, hospitalization_id pairs\n",
    "if hospitalization_df.shape[0] != hospitalization_df.unique(subset=[\"patient_id\", \"hospitalization_id\"]).shape[0]:\n",
    "    print(\"Warning: hospitalization_df contains duplicate (patient_id, hospitalization_id) rows.\")\n",
    "\n",
    "# Check if adt_df has duplicate patient_id, hospitalization_id, adt_event_id (or similar) triplets\n",
    "# If adt_df has an event or unique identifier column, replace 'adt_event_id' with correct column\n",
    "adt_unique_cols = [col for col in [ \"hospitalization_id\", \"in_dttm\"] if col in adt_df.columns]\n",
    "if len(adt_unique_cols) >= 2 and adt_df.shape[0] != adt_df.unique(subset=adt_unique_cols).shape[0]:\n",
    "    print(\"Warning: adt_df contains duplicate rows for identifier columns:\", adt_unique_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43def308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter hospitalization_df and adt_df down to all_decedent_hosp_ids\n",
    "hospitalization_df_subset = hospitalization_df.filter(\n",
    "    pl.col(\"patient_id\").is_in(all_decedent_patient_ids)\n",
    ")\n",
    "all_decedent_hosp_ids = hospitalization_df_subset.select('hospitalization_id').to_series().to_list()\n",
    "adt_df_subset = adt_df.filter(\n",
    "    pl.col(\"hospitalization_id\").is_in(all_decedent_hosp_ids)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_stitched, adt_stitched, encounter_mapping = stitch_encounters(\n",
    "      hospitalization=hospitalization_df_subset.to_pandas(),\n",
    "      adt=adt_df_subset.to_pandas(),\n",
    "      time_interval=12\n",
    "  )\n",
    "\n",
    "hosp_stitched = pl.from_pandas(hosp_stitched)\n",
    "adt_stitched = pl.from_pandas(adt_stitched)\n",
    "\n",
    "# Ensure encounter_block is int32 (if present)\n",
    "hosp_stitched = hosp_stitched.with_columns(\n",
    "    pl.col(\"encounter_block\").cast(pl.Int32)\n",
    ")\n",
    "adt_stitched = adt_stitched.with_columns(\n",
    "    pl.col(\"encounter_block\").cast(pl.Int32)\n",
    ")\n",
    "\n",
    "# Filter hosp_stitched to only hospitalizations that are present in the adt_stitched table\n",
    "# assuming 'hospitalization_id' is the matching key\n",
    "# (if there are multiple relevant keys, adjust accordingly)\n",
    "if \"hospitalization_id\" in hosp_stitched.columns and \"hospitalization_id\" in adt_stitched.columns:\n",
    "    hosp_stitched = (\n",
    "        hosp_stitched.filter(\n",
    "            pl.col(\"hospitalization_id\").is_in(adt_stitched[\"hospitalization_id\"].unique())\n",
    "        )\n",
    "    )\n",
    "encounter_mapping = pl.from_pandas(encounter_mapping)\n",
    "encounter_mapping = encounter_mapping.with_columns(\n",
    "    pl.col(\"encounter_block\").cast(pl.Int32)\n",
    ")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb72d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify expired encounters\n",
    "decedents_df = hosp_stitched.filter(\n",
    "    pl.col('discharge_category').str.to_lowercase() == 'expired'\n",
    ")\n",
    "\n",
    "# Make hospitalization subset for expired\n",
    "# Join patient_id and death_dttm from patient_df to final_df\n",
    "\n",
    "final_df = (\n",
    "    decedents_df\n",
    "    .select([\n",
    "        'patient_id',\n",
    "        'hospitalization_id',\n",
    "        'encounter_block',\n",
    "        'admission_dttm',\n",
    "        'discharge_dttm', # discharge datetime for the death hospitalization\n",
    "        \"age_at_admission\", \n",
    "        \"discharge_category\",\n",
    "        \"admission_type_category\"\n",
    "    ])\n",
    "    .with_columns([\n",
    "        pl.col(\"discharge_category\").str.to_lowercase(),\n",
    "        pl.col(\"admission_type_category\").str.to_lowercase()\n",
    "    ])\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "# Now join patient_id and death_dttm from patient_df to final_df\n",
    "demog_cols = ['patient_id', 'death_dttm', 'race_category', 'sex_category','ethnicity_category' ]\n",
    "final_df = final_df.join(\n",
    "    patient_df.select(demog_cols), on='patient_id', how='left'\n",
    ")\n",
    "\n",
    "decedents_df_n = final_df[\"patient_id\"].n_unique()\n",
    "strobe_counts[\"1_decedents_df_n\"] = decedents_df_n\n",
    "strobe_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af00488b",
   "metadata": {},
   "source": [
    "# Final outcome dttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295eb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_filepath = f\"{tables_path}/clif_vitals.{file_type}\"\n",
    "vitals_df = read_data(\n",
    "      vitals_filepath,\n",
    "      file_type,\n",
    "      filter_ids=all_decedent_hosp_ids,\n",
    "      id_column='hospitalization_id'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b27823",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_df = apply_outlier_handling(vitals_df, 'vitals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7124ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, sort by recorded_dttm within each hospitalization_id\n",
    "vitals_df = (\n",
    "    vitals_df\n",
    "    .sort(['hospitalization_id', 'recorded_dttm'])\n",
    ")\n",
    "\n",
    "\n",
    "# Get first and last recorded_dttm, plus last weight and height for each hospitalization\n",
    "vitals_first_last = (\n",
    "    vitals_df\n",
    "    .group_by('hospitalization_id')\n",
    "    .agg([\n",
    "        pl.col('recorded_dttm').min().alias('first_recorded_vital_dttm'),\n",
    "        pl.col('recorded_dttm').max().alias('last_recorded_vital_dttm'),\n",
    "\n",
    "        # Get last recorded weight\n",
    "        pl.col('vital_value')\n",
    "            .filter(pl.col('vital_category') == 'weight_kg')\n",
    "            .last()\n",
    "            .alias('last_weight_kg'),\n",
    "\n",
    "        # Get last recorded height\n",
    "        pl.col('vital_value')\n",
    "            .filter(pl.col('vital_category') == 'height_cm')\n",
    "            .last()\n",
    "            .alias('last_height_cm')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Calculate BMI\n",
    "vitals_first_last = vitals_first_last.with_columns(\n",
    "    (pl.col('last_weight_kg') / ((pl.col('last_height_cm') / 100) ** 2)).alias('bmi')\n",
    ")\n",
    "\n",
    "# Join with final_df\n",
    "final_df = final_df.join(vitals_first_last, on='hospitalization_id', how='left')\n",
    "\n",
    "# Define final_death_dttm as death_dttm, if missing then last_recorded_vital_dttm\n",
    "final_df = final_df.with_columns(\n",
    "    pl.when(pl.col(\"death_dttm\").is_not_null())\n",
    "      .then(pl.col(\"death_dttm\"))\n",
    "      .otherwise(pl.col(\"last_recorded_vital_dttm\"))\n",
    "      .alias(\"final_death_dttm\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072791da",
   "metadata": {},
   "source": [
    "# Inpatient decedents\n",
    "\n",
    "Identify inpatient encounters - location must be ed, ward, stepdown, icu at last_recorded_vital_dttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e73d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_locations = ['ed', 'ward', 'stepdown', 'icu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee5e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all decedents are present in ADT table\n",
    "decedent_hosp_in_adt = set(adt_df.select('hospitalization_id').to_series().to_list())\n",
    "missing_in_adt = set(all_decedent_hosp_ids) - decedent_hosp_in_adt\n",
    "\n",
    "if missing_in_adt:\n",
    "    print(f\"Warning: {len(missing_in_adt)} hospitalization(s) missing in ADT table\")\n",
    "    print(f\"Missing hospitalization_ids: {missing_in_adt}\")\n",
    "else:\n",
    "    print(f\"✓ All {len(all_decedent_hosp_ids)} decedent hospitalizations present in ADT table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a599fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_location_per_hosp = (\n",
    "      adt_df\n",
    "      .filter(pl.col('hospitalization_id').is_in(all_decedent_hosp_ids))\n",
    "      .sort('out_dttm', descending=True)\n",
    "      .group_by('hospitalization_id')\n",
    "      .agg([\n",
    "          pl.col('location_category').first().alias('last_location_category'),\n",
    "          pl.col('location_name').first().alias('last_location_name'),\n",
    "          pl.col('out_dttm').first().alias('last_location_out_dttm'),\n",
    "          (pl.col('location_category').str.to_lowercase() == 'icu').any().alias('ever_icu'),\n",
    "          (pl.col('location_category').str.to_lowercase() == 'ward').any().alias('ever_ward'),\n",
    "          (pl.col('location_category').str.to_lowercase() == 'ed').any().alias('ever_ed'),\n",
    "          (pl.col('location_category').str.to_lowercase() == 'stepdown').any().alias('ever_stepdown'),\n",
    "          pl.col('location_category').unique().sort().alias('all_locations')\n",
    "      ])\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b93e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.join(\n",
    "    last_location_per_hosp,\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e483e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the number of hospitalizations where ever_icu, ever_ward, ever_ed, ever_stepdown are all False or null\n",
    "n_all_locs_false = final_df.filter(\n",
    "    ~(pl.col('ever_icu').fill_null(False) | \n",
    "      pl.col('ever_ward').fill_null(False) | \n",
    "      pl.col('ever_ed').fill_null(False) | \n",
    "      pl.col('ever_stepdown').fill_null(False))\n",
    ").height\n",
    "print(f\"Number of hospitalizations where all four location flags are False/null: {n_all_locs_false}\")\n",
    "\n",
    "# Create final_cohort_df dropping those hospitalizations\n",
    "final_cohort_df = final_df.filter(\n",
    "    (pl.col('ever_icu').fill_null(False) | \n",
    "     pl.col('ever_ward').fill_null(False) | \n",
    "     pl.col('ever_ed').fill_null(False) | \n",
    "     pl.col('ever_stepdown').fill_null(False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_decedent_inpatient_patient_ids = final_cohort_df.select('patient_id').to_series().to_list()\n",
    "all_decedent_inpatient_hosp_ids = final_cohort_df.select('hospitalization_id').to_series().to_list()\n",
    "strobe_counts[\"2_inpatient_decedents\"] = len(all_decedent_inpatient_patient_ids)\n",
    "strobe_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adt_stitched.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039c3b3",
   "metadata": {},
   "source": [
    "# ADT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a819425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hospital and ICU length of stay using approach similar to the provided reference (adapted for Polars)\n",
    "\n",
    "# Filter adt_df to only the relevant hospitalizations\n",
    "adt_in_cohort = adt_stitched.filter(pl.col(\"hospitalization_id\").is_in(all_decedent_inpatient_hosp_ids))\n",
    "\n",
    "# Lowercase location_category (just the column, not the whole DataFrame)\n",
    "adt_in_cohort = adt_in_cohort.with_columns(\n",
    "    pl.col(\"location_category\").str.to_lowercase().alias(\"location_category\")\n",
    ")\n",
    "\n",
    "# Hospital admission summary per encounter_block: first in and last out, first admission location\n",
    "hosp_admission_summary = (\n",
    "    adt_in_cohort\n",
    "    .group_by(\"encounter_block\")\n",
    "    .agg([\n",
    "        pl.col(\"in_dttm\").min().alias(\"min_in_dttm\"),\n",
    "        pl.col(\"out_dttm\").max().alias(\"max_out_dttm\"),\n",
    "        pl.col(\"location_category\").first().alias(\"first_admission_location\")\n",
    "    ])\n",
    "    .with_columns([\n",
    "        ((pl.col(\"max_out_dttm\") - pl.col(\"min_in_dttm\")).dt.total_days()).alias(\"hospital_length_of_stay_days\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Join first_admission_location and hospital_length_of_stay_days to final_cohort_df on encounter_block\n",
    "final_cohort_df = final_cohort_df.join(\n",
    "    hosp_admission_summary.select([\n",
    "        \"encounter_block\", \n",
    "        \"first_admission_location\", \n",
    "        \"hospital_length_of_stay_days\"\n",
    "    ]),\n",
    "    on=\"encounter_block\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Restrict to ICU stays only\n",
    "icu_df = adt_in_cohort.filter(pl.col(\"location_category\") == \"icu\")\n",
    "\n",
    "# Find first ICU admission per encounter_block\n",
    "first_icu_in = (\n",
    "    icu_df\n",
    "    .group_by(\"encounter_block\")\n",
    "    .agg(pl.col(\"in_dttm\").min().alias(\"first_icu_in_dttm\"))\n",
    ")\n",
    "\n",
    "# Join back to get corresponding out_dttm for the first ICU in_dttm\n",
    "icu_summary = (\n",
    "    first_icu_in.join(\n",
    "        icu_df.select([\"encounter_block\", \"in_dttm\", \"out_dttm\"]),\n",
    "        left_on=[\"encounter_block\", \"first_icu_in_dttm\"],\n",
    "        right_on=[\"encounter_block\", \"in_dttm\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .with_columns([\n",
    "        pl.col(\"out_dttm\").alias(\"first_icu_out_dttm\"),\n",
    "        ((pl.col(\"out_dttm\") - pl.col(\"first_icu_in_dttm\")).dt.total_seconds() / (3600*24)).alias(\"first_icu_los_days\")\n",
    "    ])\n",
    "    .select([\n",
    "        \"encounter_block\", \"first_icu_in_dttm\", \"first_icu_out_dttm\", \"first_icu_los_days\"\n",
    "    ])\n",
    ")\n",
    "\n",
    "final_cohort_df = final_cohort_df.join(\n",
    "    icu_summary.select([\n",
    "        \"encounter_block\", \n",
    "        \"first_icu_los_days\"\n",
    "    ]),\n",
    "    on=\"encounter_block\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Now, hosp_admission_summary contains hospital LOS and first_admission_location, and icu_summary contains first ICU LOS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa933cf",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0327a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age < 75\n",
    "final_cohort_df = final_cohort_df.join(\n",
    "    patient_df.select(['patient_id', 'birth_date']),\n",
    "    on='patient_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate age at death as (discharge_dttm - birth_date) in years (using .dt.total_days()/365.25)\n",
    "final_cohort_df = final_cohort_df.with_columns(\n",
    "    (\n",
    "        (pl.col('final_death_dttm') - pl.col('birth_date')).dt.total_days() / 365.25\n",
    "    ).alias('age_at_death')\n",
    ")\n",
    "\n",
    "# Create age_75_less flag per patient_id ( age_at_death <= 75)\n",
    "age_flag_df = (\n",
    "    final_cohort_df\n",
    "    .group_by('patient_id')\n",
    "    .agg([\n",
    "        (\n",
    "            (pl.col('age_at_death') <= 75).any()\n",
    "        ).alias('age_75_less')\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Join age_75_less flag onto final_df; fill nulls with False\n",
    "final_cohort_df = (\n",
    "    final_cohort_df\n",
    "    .join(age_flag_df, on='patient_id', how='left')\n",
    "    .with_columns(\n",
    "        pl.col('age_75_less').fill_null(False)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Filter age < 75 using the flag, not the missing column\n",
    "age_relevant_cohort = final_cohort_df.filter(\n",
    "    pl.col('age_75_less') == True\n",
    ")\n",
    "age_relevant_cohort_n = age_relevant_cohort[\"patient_id\"].n_unique()\n",
    "strobe_counts[\"3_age_relevant_cohort_n\"] = age_relevant_cohort_n\n",
    "strobe_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ed2a4",
   "metadata": {},
   "source": [
    "# ICD Codes\n",
    "\n",
    "The CALC criteria includes the following as cause:\n",
    "- I20–I25: ischemic heart disease\n",
    "- I60–I69: cerebrovascular disease\n",
    "- V01–Y89: external causes (e.g., blunt trauma, gunshot wounds, overdose, suicide, drowning, asphyxiation)\n",
    "\n",
    "[Reference](https://www.cms.gov/files/document/112020-opo-final-rule-cms-3380-f.pdf)\n",
    "\n",
    "We also flag contraindications of sepsis and cancer using ICD10 codes. We use the ICD codes for these specified in utils/icd10_contraindications.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hospial_dx_filepath = f\"{tables_path}/clif_hospital_diagnosis.{file_type}\"\n",
    "# hospital_dx = read_data(\n",
    "#     hospial_dx_filepath,\n",
    "#     file_type,\n",
    "#     filter_ids=all_decedent_inpatient_hosp_ids,\n",
    "#     id_column='hospitalization_id'\n",
    "# )\n",
    "\n",
    "# # Join on hospitalization_id to add patient_id from final_cohort_df to hospital_dx\n",
    "# hospital_dx = (\n",
    "#     hospital_dx.join(\n",
    "#         final_cohort_df.select(['hospitalization_id', 'patient_id']),\n",
    "#         on='hospitalization_id',\n",
    "#         how='left'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Show how many hosp ids from all_decedent_inpatient_hosp_ids are present in hospital_dx\n",
    "# present_hosp_ids = set(hospital_dx['hospitalization_id'].unique())\n",
    "# requested_hosp_ids = set(all_decedent_inpatient_hosp_ids)\n",
    "# n_present = len(present_hosp_ids & requested_hosp_ids)\n",
    "# n_requested = len(requested_hosp_ids)\n",
    "# print(f\"Hospitalization IDs present in hospital_dx: {n_present} out of {n_requested}\")\n",
    "\n",
    "# # Add these counts to strobe_counts\n",
    "# strobe_counts[\"5_present_inpatient_hospitalization_ids_in_hospital_dx\"] = n_present\n",
    "\n",
    "# # Add count: how many age_relevant_cohort patients are present in hospital_dx\n",
    "# age_relevant_patient_ids = set(age_relevant_cohort['patient_id'].unique())\n",
    "# hospital_dx_patient_ids = set(hospital_dx['patient_id'].unique())\n",
    "# n_age_relevant_in_hospital_dx = len(age_relevant_patient_ids & hospital_dx_patient_ids)\n",
    "# strobe_counts[\"5_age_relevant_in_hospital_dx\"] = n_age_relevant_in_hospital_dx\n",
    "\n",
    "# strobe_counts\n",
    "\n",
    "\n",
    "\n",
    "# SKIP the join here - it crashes with large data\n",
    "# patient_id will be added later at line 514 via hospitalization_df join\n",
    "\n",
    "# SKIP the counts - they cause .unique() crashes\n",
    "# These are just for reporting, not essential for analysis\n",
    "print(\"Skipping hospitalization ID counts to avoid kernel crash\")\n",
    "print(\"(Counts will be skipped in strobe_counts)\")\n",
    "\n",
    "# Continue to ICD code processing below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b298035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "# Load hospital_dx WITHOUT any join (avoid crash)\n",
    "hospial_dx_filepath = f\"{tables_path}/clif_hospital_diagnosis.{file_type}\"\n",
    "hospital_dx = read_data(\n",
    "    hospial_dx_filepath,\n",
    "    file_type,\n",
    "    filter_ids=all_decedent_inpatient_hosp_ids,\n",
    "    id_column='hospitalization_id'\n",
    ")\n",
    "\n",
    "print(f\"✓ Loaded hospital_dx: {len(hospital_dx)} rows\")\n",
    "\n",
    "# ---- Load contraindications ----\n",
    "contraindications_df = pl.read_csv(str(UTILS_DIR / \"icd10_contraindications.csv\"))\n",
    "contraindication_codes = (\n",
    "    contraindications_df\n",
    "    .with_columns([\n",
    "        pl.col(\"ICD-10-CM\")\n",
    "            .cast(pl.Utf8)\n",
    "            .str.to_lowercase()\n",
    "            .str.replace_all(r\"[.\\s]\", \"\")\n",
    "            .alias(\"code_norm\")\n",
    "    ])\n",
    "    .select(\"code_norm\")\n",
    "    .to_series()\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(contraindication_codes)} contraindication codes\")\n",
    "\n",
    "contraindication_codes_df = pd.DataFrame({'code': contraindication_codes})\n",
    "all_ids_df = pd.DataFrame({'hospitalization_id': list(all_decedent_inpatient_hosp_ids)})\n",
    "\n",
    "query = f\"\"\"\n",
    "WITH hospital_dx_normalized AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        LOWER(REGEXP_REPLACE(diagnosis_code, '[.\\\\s]', '', 'g')) AS dx_norm,\n",
    "        LOWER(diagnosis_code_format) AS sys\n",
    "    FROM read_parquet('{hospial_dx_filepath}')\n",
    "    WHERE hospitalization_id IN (SELECT hospitalization_id FROM all_ids_df)\n",
    "),\n",
    "hospital_dx_flags AS (\n",
    "    SELECT\n",
    "        hospitalization_id,\n",
    "        CASE \n",
    "            WHEN sys IN ('icd10', 'icd10cm') AND REGEXP_MATCHES(dx_norm, '^i2[0-5]\\\\w*$') THEN true \n",
    "            ELSE false \n",
    "        END AS icd10_ischemic,\n",
    "        CASE \n",
    "            WHEN sys IN ('icd10', 'icd10cm') AND REGEXP_MATCHES(dx_norm, '^i6[0-9]\\\\w*$') THEN true \n",
    "            ELSE false \n",
    "        END AS icd10_cerebro,\n",
    "        CASE \n",
    "            WHEN sys IN ('icd10', 'icd10cm') AND REGEXP_MATCHES(dx_norm, '^(v0[1-9]|v[1-9]\\\\d|w\\\\d{{2}}|x\\\\d{{2}}|y[0-8]\\\\d)\\\\w*$') THEN true \n",
    "            ELSE false \n",
    "        END AS icd10_external,\n",
    "        CASE \n",
    "            WHEN sys IN ('icd10', 'icd10cm') AND dx_norm IN (SELECT code FROM contraindication_codes_df) THEN true \n",
    "            ELSE false \n",
    "        END AS icd10_contraindication\n",
    "    FROM hospital_dx_normalized\n",
    "),\n",
    "hospital_dx_with_patient AS (\n",
    "    SELECT h.*, hosp.patient_id\n",
    "    FROM hospital_dx_flags h\n",
    "    LEFT JOIN hospitalization_df hosp ON h.hospitalization_id = hosp.hospitalization_id\n",
    ")\n",
    "SELECT\n",
    "    patient_id,\n",
    "    BOOL_OR(icd10_ischemic) AS icd10_ischemic,\n",
    "    BOOL_OR(icd10_cerebro) AS icd10_cerebro,\n",
    "    BOOL_OR(icd10_external) AS icd10_external,\n",
    "    BOOL_OR(icd10_contraindication) AS icd10_contraindication\n",
    "FROM hospital_dx_with_patient\n",
    "WHERE patient_id IS NOT NULL\n",
    "GROUP BY patient_id\n",
    "\"\"\"\n",
    "\n",
    "print(\"Processing ICD flags with DuckDB (FIXED REGEX)...\")\n",
    "patient_cause_flags_pd = duckdb.sql(query).df()\n",
    "patient_cause_flags = pl.from_pandas(patient_cause_flags_pd)\n",
    "\n",
    "print(f\"✓ Processed {len(patient_cause_flags)} patients\")\n",
    "print(f\"\\nFlag counts:\")\n",
    "print(f\"  icd10_ischemic: {patient_cause_flags['icd10_ischemic'].sum()}\")\n",
    "print(f\"  icd10_cerebro: {patient_cause_flags['icd10_cerebro'].sum()}\")\n",
    "print(f\"  icd10_external: {patient_cause_flags['icd10_external'].sum()}\")\n",
    "print(f\"  icd10_contraindication: {patient_cause_flags['icd10_contraindication'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join flags to final_df on patient_id; fill null flags to False ----\n",
    "final_cohort_df = (\n",
    "    final_cohort_df\n",
    "    .join(patient_cause_flags, on=\"patient_id\", how=\"left\")\n",
    "    .with_columns([\n",
    "        pl.col(\"icd10_ischemic\").fill_null(False),\n",
    "        pl.col(\"icd10_cerebro\").fill_null(False),\n",
    "        pl.col(\"icd10_external\").fill_null(False),\n",
    "        pl.col(\"icd10_contraindication\").fill_null(False),\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Count patients with any of: ischemic OR cerebrovascular OR external cause (CALC cause, no age/location applied)\n",
    "calc_cause_n = final_cohort_df.filter(\n",
    "    pl.col(\"icd10_ischemic\") | pl.col(\"icd10_cerebro\") | pl.col(\"icd10_external\")\n",
    ")[\"patient_id\"].n_unique()\n",
    "strobe_counts[\"calc_cause\"] = calc_cause_n\n",
    "\n",
    "# Count patients with calc_cause (any cause) AND no contraindications\n",
    "calc_cause_no_contraindication_n = final_cohort_df.filter(\n",
    "    (pl.col(\"icd10_ischemic\") | pl.col(\"icd10_cerebro\") | pl.col(\"icd10_external\")) & ~pl.col(\"icd10_contraindication\")\n",
    ")[\"patient_id\"].n_unique()\n",
    "strobe_counts[\"calc_cause_no_contraindication\"] = calc_cause_no_contraindication_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f869f4",
   "metadata": {},
   "source": [
    "# CALC Criteria\n",
    "\n",
    "CMS adopts the Cause, Age, and Location-consistent (CALC) method to define “death consistent with organ donation” for donor-potential calculations:\n",
    "\n",
    "- **Age**: deaths ≤75 years\n",
    "- **Location**: inpatient deaths (death occurs in the hospital)\n",
    "- **Cause** (ICD-10-CM, inclusion ranges):\n",
    "    - I20–I25: ischemic heart disease\n",
    "    - I60–I69: cerebrovascular disease\n",
    "    - V01–Y89: external causes (e.g., blunt trauma, gunshot wounds, overdose, suicide, drowning, asphyxiation)\n",
    "\n",
    "\n",
    "[Reference](https://www.cms.gov/files/document/112020-opo-final-rule-cms-3380-f.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a21dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort_df = final_cohort_df.with_columns(\n",
    "    (\n",
    "        (pl.col('age_75_less')) &\n",
    "        (pl.col('icd10_ischemic') | pl.col('icd10_cerebro') | pl.col('icd10_external')) &\n",
    "        (~pl.col('icd10_contraindication'))\n",
    "    ).alias('calc_flag')\n",
    ")\n",
    "\n",
    "# Count for STROBE tracking\n",
    "calc_qualified_n = final_cohort_df.filter(pl.col('calc_flag'))['patient_id'].n_unique()\n",
    "strobe_counts[\"calc_qualified\"] = calc_qualified_n\n",
    "\n",
    "print(f\"\\nCALC flag qualified: {calc_qualified_n} patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad32ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_fixed = f\"\"\"\n",
    "WITH test_data AS (\n",
    "    SELECT \n",
    "        diagnosis_code,\n",
    "        LOWER(REGEXP_REPLACE(diagnosis_code, '[.\\\\s]', '', 'g')) AS dx_norm,\n",
    "        LOWER(diagnosis_code_format) AS sys\n",
    "    FROM read_parquet('{hospial_dx_filepath}')\n",
    "    WHERE diagnosis_code LIKE 'I2%'\n",
    "    LIMIT 20\n",
    ")\n",
    "SELECT\n",
    "    diagnosis_code,\n",
    "    dx_norm,\n",
    "    sys,\n",
    "    CASE \n",
    "        WHEN sys IN ('icd10', 'icd10cm') AND REGEXP_MATCHES(dx_norm, '^i2[0-5]\\\\w*$') THEN true \n",
    "        ELSE false \n",
    "    END AS icd10_ischemic_flag\n",
    "FROM test_data\n",
    "\"\"\"\n",
    "\n",
    "test_fixed = duckdb.sql(test_case_fixed).df()\n",
    "print(test_fixed)\n",
    "print(f\"\\nTrue count: {test_fixed['icd10_ischemic_flag'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143bfbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb8419",
   "metadata": {},
   "source": [
    "# IMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_filepath = f\"{tables_path}/clif_respiratory_support.{file_type}\"\n",
    "resp_df = read_data(\n",
    "      resp_filepath,\n",
    "      file_type,\n",
    "      filter_ids=all_decedent_inpatient_hosp_ids,\n",
    "      id_column='hospitalization_id'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMV - use DuckDB to avoid loading large file into Polars\n",
    "print(\"Processing IMV data with DuckDB...\")\n",
    "\n",
    "# Create temp dataframe with needed columns from final_cohort\n",
    "final_cohort_for_imv = final_cohort_df.select([\n",
    "    \"hospitalization_id\", \"patient_id\", \"encounter_block\", \"final_death_dttm\"\n",
    "]).to_pandas()\n",
    "\n",
    "imv_query = f\"\"\"\n",
    "WITH imv_data AS (\n",
    "    SELECT \n",
    "        hospitalization_id,\n",
    "        recorded_dttm,\n",
    "        device_category\n",
    "    FROM read_parquet('{tables_path}/clif_respiratory_support.{file_type}')\n",
    "    WHERE LOWER(device_category) = 'imv'\n",
    "        AND hospitalization_id IN (SELECT hospitalization_id FROM final_cohort_for_imv)\n",
    "),\n",
    "imv_with_death AS (\n",
    "    SELECT \n",
    "        i.hospitalization_id,\n",
    "        i.recorded_dttm,\n",
    "        f.patient_id,\n",
    "        f.encounter_block,\n",
    "        f.final_death_dttm,\n",
    "        EXTRACT(EPOCH FROM (f.final_death_dttm - i.recorded_dttm)) / 3600 AS hr_2death_last_imv\n",
    "    FROM imv_data i\n",
    "    INNER JOIN final_cohort_for_imv f ON i.hospitalization_id = f.hospitalization_id\n",
    "),\n",
    "-- CHANGED: Get latest record FIRST from ALL records (not just within 48h)\n",
    "latest_imv_per_patient AS (\n",
    "    SELECT \n",
    "        patient_id,\n",
    "        hospitalization_id,\n",
    "        encounter_block,\n",
    "        final_death_dttm,\n",
    "        recorded_dttm,\n",
    "        hr_2death_last_imv,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY patient_id \n",
    "            ORDER BY recorded_dttm DESC, hospitalization_id ASC\n",
    "        ) AS rn\n",
    "    FROM imv_with_death  -- ← Using ALL records, not pre-filtered\n",
    ")\n",
    "-- CHANGED: Apply time window filter AFTER selecting latest\n",
    "SELECT \n",
    "    patient_id,\n",
    "    hospitalization_id,\n",
    "    encounter_block,\n",
    "    final_death_dttm,\n",
    "    recorded_dttm,\n",
    "    hr_2death_last_imv\n",
    "FROM latest_imv_per_patient\n",
    "WHERE rn = 1  -- Get the latest record first\n",
    "    AND hr_2death_last_imv <= 48   -- Then filter to time window\n",
    "    AND hr_2death_last_imv >= -24\n",
    "\"\"\"\n",
    "\n",
    "resp_expired_cohort = duckdb.sql(imv_query).df()\n",
    "resp_expired_cohort = pl.from_pandas(resp_expired_cohort)\n",
    "\n",
    "imv_48hr_expire = resp_expired_cohort[\"patient_id\"].n_unique()\n",
    "print(f\"✓ Patients on IMV within 48h of death: {imv_48hr_expire}\")\n",
    "\n",
    "strobe_counts[\"6_imv_48hr_expire\"] = imv_48hr_expire\n",
    "\n",
    "# Create flag\n",
    "imv_48hr_expire_patients = resp_expired_cohort.select([\"patient_id\"]).unique()\n",
    "imv_48hr_expire_patients = imv_48hr_expire_patients.with_columns(\n",
    "    pl.lit(True).alias(\"imv_48hr_expire\")\n",
    ")\n",
    "\n",
    "final_cohort_df = final_cohort_df.join(imv_48hr_expire_patients, on=\"patient_id\", how=\"left\")\n",
    "final_cohort_df = final_cohort_df.with_columns(\n",
    "    pl.col(\"imv_48hr_expire\").fill_null(False)\n",
    ")\n",
    "\n",
    "print(f\"✓ IMV processing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbf977",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort_df = final_cohort_df.join(imv_48hr_expire_patients, on=\"patient_id\", how=\"left\")\n",
    "final_cohort_df = final_cohort_df.with_columns(\n",
    "    pl.col(\"imv_48hr_expire\").fill_null(False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a57608",
   "metadata": {},
   "source": [
    "# Organ quality check\n",
    "\n",
    "Pass the potential organ quality assessment check (independent assessment) using last recorded lab values, as defined by CMS\n",
    "* Kidney: recorded creatinine, cr  <4  AND not on CRRT\n",
    "* Liver: recorded TB, AST, ALT and Total bilirubin < 4, AST < 700, AND ALT< 700\n",
    "* BMI <=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7409513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crrt_filepath = f\"{tables_path}/clif_crrt_therapy.{file_type}\"\n",
    "# labs_filepath = f\"{tables_path}/clif_labs.{file_type}\"\n",
    "# crrt_therapy = read_data(\n",
    "#       crrt_filepath,\n",
    "#       file_type,\n",
    "#       filter_ids=all_decedent_inpatient_hosp_ids,\n",
    "#       id_column='hospitalization_id'\n",
    "#   )\n",
    "\n",
    "# labs_df = read_data(\n",
    "#       labs_filepath,\n",
    "#       file_type,\n",
    "#       filter_ids=all_decedent_inpatient_hosp_ids,\n",
    "#       id_column='hospitalization_id'\n",
    "#   )\n",
    "\n",
    "# labs_df = apply_outlier_handling(labs_df, 'labs')\n",
    "\n",
    "# # ============================================\n",
    "# # Prepare final cohort with timing info\n",
    "# # ============================================\n",
    "# final_cohort_for_labs = final_cohort_df.select([\n",
    "#     \"patient_id\",\n",
    "#     \"hospitalization_id\",\n",
    "#     \"final_death_dttm\",\n",
    "# ])\n",
    "\n",
    "# # ============================================\n",
    "# # Filter labs to those recorded BEFORE final_death_dttm\n",
    "# # ============================================\n",
    "# labs_before_last_vital = (\n",
    "#     labs_df\n",
    "#     .join(\n",
    "#         final_cohort_for_labs,\n",
    "#         on='hospitalization_id',\n",
    "#         how='inner'\n",
    "#     )\n",
    "#     .filter(pl.col('lab_collect_dttm') <= pl.col('final_death_dttm'))\n",
    "# )\n",
    "\n",
    "# # ============================================\n",
    "# # Get CREATININE - last value before last vital\n",
    "# # ============================================\n",
    "# creatinine_labs = labs_before_last_vital.filter(\n",
    "#     pl.col('lab_category') == 'creatinine'\n",
    "# )\n",
    "\n",
    "# latest_creatinine = (\n",
    "#     creatinine_labs\n",
    "#     .sort('lab_collect_dttm')\n",
    "#     .group_by('hospitalization_id')\n",
    "#     .agg([\n",
    "#         pl.col('lab_collect_dttm').last().alias('creatinine_dttm'),\n",
    "#         pl.col('lab_value_numeric').last().alias('creatinine_value')\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "# # ============================================\n",
    "# # Get LIVER LABS - last values before last vital\n",
    "# # ============================================\n",
    "# liver_labs_categories = labs_before_last_vital.filter(\n",
    "#     pl.col('lab_category').is_in(['bilirubin_total', 'ast', 'alt'])\n",
    "# )\n",
    "\n",
    "# # Get values pivoted by category\n",
    "# latest_liver_values = (\n",
    "#     liver_labs_categories\n",
    "#     .sort('lab_collect_dttm')\n",
    "#     .group_by(['hospitalization_id', 'lab_category'])\n",
    "#     .agg(pl.col('lab_value_numeric').last().alias('lab_value'))\n",
    "#     .pivot(\n",
    "#         values='lab_value',\n",
    "#         index='hospitalization_id',\n",
    "#         on='lab_category'\n",
    "#     )\n",
    "#     .rename({\n",
    "#         'bilirubin_total': 'bilirubin_total_value',\n",
    "#         'ast': 'ast_value',\n",
    "#         'alt': 'alt_value'\n",
    "#     })\n",
    "# )\n",
    "\n",
    "# # Get collection datetimes for each lab\n",
    "# latest_liver_datetimes = (\n",
    "#     liver_labs_categories\n",
    "#     .sort('lab_collect_dttm')\n",
    "#     .group_by(['hospitalization_id', 'lab_category'])\n",
    "#     .agg(pl.col('lab_collect_dttm').last().alias('lab_dttm'))\n",
    "#     .pivot(\n",
    "#         values='lab_dttm',\n",
    "#         index='hospitalization_id',\n",
    "#         on='lab_category'\n",
    "#     )\n",
    "#     .rename({\n",
    "#         'bilirubin_total': 'bilirubin_total_dttm',\n",
    "#         'ast': 'ast_dttm',\n",
    "#         'alt': 'alt_dttm'\n",
    "#     })\n",
    "# )\n",
    "\n",
    "# # ============================================\n",
    "# # Combine all lab values into one dataframe\n",
    "# # ============================================\n",
    "# organ_labs = (\n",
    "#     final_cohort_for_labs\n",
    "#     .join(latest_creatinine, on='hospitalization_id', how='left')\n",
    "#     .join(latest_liver_values, on='hospitalization_id', how='left')\n",
    "#     .join(latest_liver_datetimes, on='hospitalization_id', how='left')\n",
    "#     .select([\n",
    "#         'patient_id',\n",
    "#         'creatinine_value',\n",
    "#         'creatinine_dttm',\n",
    "#         'bilirubin_total_value',\n",
    "#         'bilirubin_total_dttm',\n",
    "#         'ast_value',\n",
    "#         'ast_dttm',\n",
    "#         'alt_value',\n",
    "#         'alt_dttm'\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "# # print(organ_labs.head())\n",
    "# print(f\"\\nOrgan labs summary:\")\n",
    "# print(f\"  Patients with creatinine: {organ_labs.filter(pl.col('creatinine_value').is_not_null())['patient_id'].n_unique()}\")\n",
    "# print(f\"  Patients with bilirubin: {organ_labs.filter(pl.col('bilirubin_total_value').is_not_null())['patient_id'].n_unique()}\")\n",
    "# print(f\"  Patients with AST: {organ_labs.filter(pl.col('ast_value').is_not_null())['patient_id'].n_unique()}\")\n",
    "# print(f\"  Patients with ALT: {organ_labs.filter(pl.col('alt_value').is_not_null())['patient_id'].n_unique()}\")\n",
    "\n",
    "# # ============================================\n",
    "# # Check for CRRT within 48 hours before death\n",
    "# # ============================================\n",
    "\n",
    "# # Join CRRT with final cohort to get final_death_dttm\n",
    "# crrt_with_death_time = (\n",
    "#     crrt_therapy\n",
    "#     .join(\n",
    "#         final_cohort_df.select(['hospitalization_id', 'final_death_dttm']),\n",
    "#         on='hospitalization_id',\n",
    "#         how='inner'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Filter to CRRT recorded before death\n",
    "# crrt_before_death = crrt_with_death_time.filter(\n",
    "#     pl.col('recorded_dttm') <= pl.col('final_death_dttm')\n",
    "# )\n",
    "\n",
    "# # Check if within 48 hours of death\n",
    "# crrt_48h_before_death = (\n",
    "#     crrt_before_death\n",
    "#     .with_columns(\n",
    "#         (\n",
    "#             (pl.col('final_death_dttm') - pl.col('recorded_dttm')).dt.total_seconds() / 3600\n",
    "#         ).alias('hrs_before_death')\n",
    "#     )\n",
    "#     .filter(\n",
    "#         (pl.col('hrs_before_death') <= 48) & \n",
    "#         (pl.col('hrs_before_death') >= 0)\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Create flag: any CRRT within 48h of death\n",
    "# on_crrt_flag = (\n",
    "#     crrt_48h_before_death\n",
    "#     .select('hospitalization_id')\n",
    "#     .unique()\n",
    "#     .with_columns(pl.lit(True).alias('on_crrt_48h_before_death'))\n",
    "# )\n",
    "\n",
    "# # Join flag to final_cohort_df\n",
    "# final_cohort_df = final_cohort_df.join(\n",
    "#     on_crrt_flag,\n",
    "#     on='hospitalization_id',\n",
    "#     how='left'\n",
    "# )\n",
    "\n",
    "# # Fill nulls with False\n",
    "# final_cohort_df = final_cohort_df.with_columns(\n",
    "#     pl.col('on_crrt_48h_before_death').fill_null(False)\n",
    "# )\n",
    "\n",
    "# # Count for tracking\n",
    "# on_crrt_n = final_cohort_df.filter(pl.col('on_crrt_48h_before_death'))['patient_id'].n_unique()\n",
    "# print(f\"Patients on CRRT within 48h before death: {on_crrt_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "crrt_filepath = f\"{tables_path}/clif_crrt_therapy.{file_type}\"\n",
    "# CRRT - use DuckDB to avoid loading large file into Polars\n",
    "print(\"Processing CRRT data with DuckDB...\")\n",
    "\n",
    "# Create temp dataframe with needed columns from final_cohort\n",
    "final_cohort_for_crrt = final_cohort_df.select([\n",
    "    \"hospitalization_id\", \"final_death_dttm\"\n",
    "]).to_pandas()\n",
    "\n",
    "crrt_query = f\"\"\"\n",
    "WITH crrt_data AS (\n",
    "    SELECT \n",
    "        hospitalization_id,\n",
    "        recorded_dttm\n",
    "    FROM read_parquet('{crrt_filepath}')\n",
    "    WHERE hospitalization_id IN (SELECT hospitalization_id FROM final_cohort_for_crrt)\n",
    "),\n",
    "crrt_with_death AS (\n",
    "    SELECT \n",
    "        c.hospitalization_id,\n",
    "        c.recorded_dttm,\n",
    "        f.final_death_dttm,\n",
    "        EXTRACT(EPOCH FROM (f.final_death_dttm - c.recorded_dttm)) / 3600 AS hrs_before_death\n",
    "    FROM crrt_data c\n",
    "    INNER JOIN final_cohort_for_crrt f ON c.hospitalization_id = f.hospitalization_id\n",
    "    WHERE c.recorded_dttm <= f.final_death_dttm\n",
    "),\n",
    "crrt_within_48h AS (\n",
    "    SELECT \n",
    "        hospitalization_id\n",
    "    FROM crrt_with_death\n",
    "    WHERE hrs_before_death <= 48 AND hrs_before_death >= 0\n",
    ")\n",
    "SELECT DISTINCT hospitalization_id\n",
    "FROM crrt_within_48h\n",
    "\"\"\"\n",
    "\n",
    "crrt_48h_result = duckdb.sql(crrt_query).df()\n",
    "crrt_48h_result = pl.from_pandas(crrt_48h_result)\n",
    "\n",
    "# Create flag\n",
    "on_crrt_flag = crrt_48h_result.with_columns(\n",
    "    pl.lit(True).alias('on_crrt_48h_before_death')\n",
    ")\n",
    "\n",
    "# Join flag to final_cohort_df\n",
    "final_cohort_df = final_cohort_df.join(\n",
    "    on_crrt_flag,\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill nulls with False\n",
    "final_cohort_df = final_cohort_df.with_columns(\n",
    "    pl.col('on_crrt_48h_before_death').fill_null(False)\n",
    ")\n",
    "\n",
    "# Count for tracking\n",
    "on_crrt_n = final_cohort_df.filter(pl.col('on_crrt_48h_before_death'))['patient_id'].n_unique()\n",
    "print(f\"✓ Patients on CRRT within 48h before death: {on_crrt_n}\")\n",
    "print(f\"✓ CRRT processing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d29ef6",
   "metadata": {},
   "source": [
    "<!-- Organ labs summary:\n",
    "  Patients with creatinine: 6188\n",
    "  Patients with bilirubin: 5960\n",
    "  Patients with AST: 5912\n",
    "  Patients with ALT: 5948 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_filepath = f\"{tables_path}/clif_labs.{file_type}\"\n",
    "# Labs - use DuckDB to avoid loading large file into Polars\n",
    "print(\"Processing Labs data with DuckDB...\")\n",
    "\n",
    "# Create temp dataframe with needed columns from final_cohort\n",
    "final_cohort_for_labs = final_cohort_df.select([\n",
    "    \"patient_id\",\n",
    "    \"hospitalization_id\",\n",
    "    \"final_death_dttm\",\n",
    "]).to_pandas()\n",
    "\n",
    "labs_query = f\"\"\"\n",
    "WITH labs_data AS (\n",
    "    SELECT \n",
    "        hospitalization_id,\n",
    "        lab_collect_dttm,\n",
    "        lab_category,\n",
    "        lab_value_numeric\n",
    "    FROM read_parquet('{labs_filepath}')\n",
    "    WHERE hospitalization_id IN (SELECT hospitalization_id FROM final_cohort_for_labs)\n",
    "),\n",
    "labs_with_death AS (\n",
    "    SELECT \n",
    "        l.hospitalization_id,\n",
    "        l.lab_collect_dttm,\n",
    "        l.lab_category,\n",
    "        l.lab_value_numeric,\n",
    "        f.patient_id,\n",
    "        f.final_death_dttm\n",
    "    FROM labs_data l\n",
    "    INNER JOIN final_cohort_for_labs f ON l.hospitalization_id = f.hospitalization_id\n",
    "    WHERE l.lab_collect_dttm <= f.final_death_dttm\n",
    "),\n",
    "-- Get latest creatinine per hospitalization\n",
    "latest_creatinine AS (\n",
    "    SELECT \n",
    "        hospitalization_id,\n",
    "        lab_value_numeric AS creatinine_value,\n",
    "        lab_collect_dttm AS creatinine_dttm\n",
    "    FROM (\n",
    "        SELECT \n",
    "            hospitalization_id,\n",
    "            lab_value_numeric,\n",
    "            lab_collect_dttm,\n",
    "            ROW_NUMBER() OVER (PARTITION BY hospitalization_id ORDER BY lab_collect_dttm DESC) AS rn\n",
    "        FROM labs_with_death\n",
    "        WHERE lab_category = 'creatinine'\n",
    "    ) ranked\n",
    "    WHERE rn = 1\n",
    "),\n",
    "-- Get latest liver labs per hospitalization\n",
    "latest_liver AS (\n",
    "    SELECT \n",
    "        hospitalization_id,\n",
    "        MAX(CASE WHEN lab_category = 'bilirubin_total' THEN lab_value_numeric END) AS bilirubin_total_value,\n",
    "        MAX(CASE WHEN lab_category = 'bilirubin_total' THEN lab_collect_dttm END) AS bilirubin_total_dttm,\n",
    "        MAX(CASE WHEN lab_category = 'ast' THEN lab_value_numeric END) AS ast_value,\n",
    "        MAX(CASE WHEN lab_category = 'ast' THEN lab_collect_dttm END) AS ast_dttm,\n",
    "        MAX(CASE WHEN lab_category = 'alt' THEN lab_value_numeric END) AS alt_value,\n",
    "        MAX(CASE WHEN lab_category = 'alt' THEN lab_collect_dttm END) AS alt_dttm\n",
    "    FROM (\n",
    "        SELECT \n",
    "            hospitalization_id,\n",
    "            lab_category,\n",
    "            lab_value_numeric,\n",
    "            lab_collect_dttm,\n",
    "            ROW_NUMBER() OVER (PARTITION BY hospitalization_id, lab_category ORDER BY lab_collect_dttm DESC) AS rn\n",
    "        FROM labs_with_death\n",
    "        WHERE lab_category IN ('bilirubin_total', 'ast', 'alt')\n",
    "    ) ranked\n",
    "    WHERE rn = 1\n",
    "    GROUP BY hospitalization_id\n",
    "),\n",
    "-- Combine all labs\n",
    "organ_labs AS (\n",
    "    SELECT DISTINCT\n",
    "        f.patient_id,\n",
    "        c.creatinine_value,\n",
    "        c.creatinine_dttm,\n",
    "        l.bilirubin_total_value,\n",
    "        l.bilirubin_total_dttm,\n",
    "        l.ast_value,\n",
    "        l.ast_dttm,\n",
    "        l.alt_value,\n",
    "        l.alt_dttm\n",
    "    FROM final_cohort_for_labs f\n",
    "    LEFT JOIN latest_creatinine c ON f.hospitalization_id = c.hospitalization_id\n",
    "    LEFT JOIN latest_liver l ON f.hospitalization_id = l.hospitalization_id\n",
    ")\n",
    "SELECT * FROM organ_labs\n",
    "\"\"\"\n",
    "\n",
    "organ_labs_result = duckdb.sql(labs_query).df()\n",
    "organ_labs = pl.from_pandas(organ_labs_result)\n",
    "\n",
    "print(f\"✓ Organ labs loaded: {len(organ_labs)} patients\")\n",
    "print(f\"  Patients with creatinine: {organ_labs.filter(pl.col('creatinine_value').is_not_null())['patient_id'].n_unique()}\")\n",
    "print(f\"  Patients with bilirubin: {organ_labs.filter(pl.col('bilirubin_total_value').is_not_null())['patient_id'].n_unique()}\")\n",
    "print(f\"  Patients with AST: {organ_labs.filter(pl.col('ast_value').is_not_null())['patient_id'].n_unique()}\")\n",
    "print(f\"  Patients with ALT: {organ_labs.filter(pl.col('alt_value').is_not_null())['patient_id'].n_unique()}\")\n",
    "\n",
    "# Join organ_labs with final_cohort_df on patient_id\n",
    "final_cohort_df = final_cohort_df.join(\n",
    "    organ_labs, \n",
    "    on='patient_id', \n",
    "    how='left', \n",
    "    suffix='_organlab'\n",
    ")\n",
    "print(f\"✓ Labs processing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a610e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join organ_labs with final_cohort_for_labs on patient_id\n",
    "final_cohort_df = final_cohort_df.join(\n",
    "    organ_labs, \n",
    "    on='patient_id', \n",
    "    how='left', \n",
    "    suffix='_organlab'\n",
    ")\n",
    "print(f\"Final cohort with organ labs shape: {final_cohort_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795592c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Create organ quality assessment flags\n",
    "# ============================================\n",
    "final_cohort_df = final_cohort_df.with_columns([\n",
    "    # Kidney criteria: creatinine < 4 AND not on CRRT\n",
    "    (\n",
    "        (pl.col('creatinine_value').is_not_null()) &\n",
    "        (pl.col('creatinine_value') < 4) &\n",
    "        (~pl.col('on_crrt_48h_before_death'))\n",
    "    ).alias('kidney_eligible'),\n",
    "\n",
    "    # Liver criteria: all three labs recorded AND values within limits\n",
    "    (\n",
    "        (pl.col('bilirubin_total_value').is_not_null()) &\n",
    "        (pl.col('ast_value').is_not_null()) &\n",
    "        (pl.col('alt_value').is_not_null()) &\n",
    "        (pl.col('bilirubin_total_value') < 4) &\n",
    "        (pl.col('ast_value') < 700) &\n",
    "        (pl.col('alt_value') < 700)\n",
    "    ).alias('liver_eligible'),\n",
    "\n",
    "    # BMI criteria: <= 50\n",
    "    (\n",
    "        (pl.col('bmi').is_not_null()) &\n",
    "        (pl.col('bmi') <= 50)\n",
    "    ).alias('bmi_eligible'),\n",
    "])\n",
    "\n",
    "# Overall: (kidney OR liver) AND BMI - done in separate call\n",
    "final_cohort_df = final_cohort_df.with_columns([\n",
    "    (\n",
    "        (\n",
    "            pl.col('kidney_eligible') | pl.col('liver_eligible')\n",
    "        ) &\n",
    "        pl.col('bmi_eligible')\n",
    "    ).alias('organ_check_pass')\n",
    "])\n",
    "\n",
    "# Count for STROBE tracking\n",
    "kidney_eligible_n = final_cohort_df.filter(pl.col('kidney_eligible'))['patient_id'].n_unique()\n",
    "liver_eligible_n = final_cohort_df.filter(pl.col('liver_eligible'))['patient_id'].n_unique()\n",
    "bmi_eligible_n = final_cohort_df.filter(pl.col('bmi_eligible'))['patient_id'].n_unique()\n",
    "organ_check_pass_n = final_cohort_df.filter(pl.col('organ_check_pass'))['patient_id'].n_unique()\n",
    "\n",
    "strobe_counts[\"organ_kidney_eligible\"] = kidney_eligible_n\n",
    "strobe_counts[\"organ_liver_eligible\"] = liver_eligible_n\n",
    "strobe_counts[\"organ_bmi_eligible\"] = bmi_eligible_n\n",
    "strobe_counts[\"organ_check_pass\"] = organ_check_pass_n\n",
    "\n",
    "print(f\"\\nOrgan Quality Assessment:\")\n",
    "print(f\"  Kidney eligible: {kidney_eligible_n} patients\")\n",
    "print(f\"  Liver eligible: {liver_eligible_n} patients\")\n",
    "print(f\"  BMI eligible: {bmi_eligible_n} patients\")\n",
    "print(f\"  Overall organ check pass: {organ_check_pass_n} patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c225063",
   "metadata": {},
   "source": [
    "# Microbiology\n",
    "\n",
    "Identify negative blood cultures and patients with no cultures in last 48h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6727d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_culture_filepath = f\"{tables_path}/clif_microbiology_culture.{file_type}\"\n",
    "micro_culture = read_data(\n",
    "      micro_culture_filepath,\n",
    "      file_type,\n",
    "      filter_ids=all_decedent_inpatient_hosp_ids,\n",
    "      id_column='hospitalization_id'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae00681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microbiology - use DuckDB to avoid Polars crashes\n",
    "print(\"Processing microbiology data with DuckDB...\")\n",
    "\n",
    "final_cohort_for_micro = final_cohort_df.select([\n",
    "    'hospitalization_id', 'final_death_dttm'\n",
    "]).to_pandas()\n",
    "\n",
    "micro_query = f\"\"\"\n",
    "WITH blood_cultures AS (\n",
    "    SELECT \n",
    "        hospitalization_id,\n",
    "        collect_dttm,\n",
    "        organism_category\n",
    "    FROM read_parquet('{tables_path}/clif_microbiology_culture.{file_type}')\n",
    "    WHERE fluid_category = 'blood_buffy'\n",
    "        AND method_category = 'culture'\n",
    "        AND hospitalization_id IN (SELECT hospitalization_id FROM final_cohort_for_micro)\n",
    "),\n",
    "cultures_with_death AS (\n",
    "    SELECT \n",
    "        b.hospitalization_id,\n",
    "        b.collect_dttm,\n",
    "        b.organism_category,\n",
    "        f.final_death_dttm,\n",
    "        EXTRACT(EPOCH FROM (f.final_death_dttm - b.collect_dttm)) / 3600 AS hrs_before_death\n",
    "    FROM blood_cultures b\n",
    "    INNER JOIN final_cohort_for_micro f ON b.hospitalization_id = f.hospitalization_id\n",
    "    WHERE b.collect_dttm IS NOT NULL\n",
    "),\n",
    "cultures_48h AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        CASE \n",
    "            WHEN LOWER(organism_category) LIKE '%no_growth%' \n",
    "                OR organism_category IS NULL \n",
    "                OR LOWER(organism_category) = '' \n",
    "            THEN true \n",
    "            ELSE false \n",
    "        END AS is_negative_culture\n",
    "    FROM cultures_with_death\n",
    "    WHERE hrs_before_death >= 0 AND hrs_before_death <= 48\n",
    "),\n",
    "positive_cultures AS (\n",
    "    SELECT DISTINCT hospitalization_id\n",
    "    FROM cultures_48h\n",
    "    WHERE is_negative_culture = false\n",
    ")\n",
    "SELECT \n",
    "    f.hospitalization_id,\n",
    "    CASE WHEN p.hospitalization_id IS NULL THEN true ELSE false END AS no_positive_culture_48hrs\n",
    "FROM final_cohort_for_micro f\n",
    "LEFT JOIN positive_cultures p ON f.hospitalization_id = p.hospitalization_id\n",
    "\"\"\"\n",
    "\n",
    "no_positive_culture_flag_pd = duckdb.sql(micro_query).df()\n",
    "no_positive_culture_flag = pl.from_pandas(no_positive_culture_flag_pd)\n",
    "\n",
    "# Join flag to final_cohort_df\n",
    "final_cohort_df = final_cohort_df.join(\n",
    "    no_positive_culture_flag,\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill any nulls with False\n",
    "final_cohort_df = final_cohort_df.with_columns(\n",
    "    pl.col('no_positive_culture_48hrs').fill_null(False)\n",
    ")\n",
    "\n",
    "# Count for STROBE tracking\n",
    "no_positive_culture_n = final_cohort_df.filter(pl.col('no_positive_culture_48hrs'))['patient_id'].n_unique()\n",
    "positive_culture_n = final_cohort_df.filter(~pl.col('no_positive_culture_48hrs'))['patient_id'].n_unique()\n",
    "\n",
    "strobe_counts[\"no_positive_culture_48hrs\"] = no_positive_culture_n\n",
    "strobe_counts[\"positive_culture_48hrs\"] = positive_culture_n\n",
    "\n",
    "print(f\"\\nBlood Culture Results:\")\n",
    "print(f\"  Patients with no positive cultures in last 48h: {no_positive_culture_n}\")\n",
    "print(f\"  Patients with positive cultures in last 48h: {positive_culture_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41096007",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b325e13",
   "metadata": {},
   "source": [
    "# CLIF Eligible Donor\n",
    "\n",
    "Medically eligible potential deceased abdominal organ donor (CLIF-eligible-donors):  \n",
    "\n",
    "\n",
    "* From ALL inpatient deaths (ensure death location = ED, ward, stepdown, ICU)\n",
    "* Age < 75\n",
    "* On invasive mechanical ventilation\n",
    "* IF death date/time available: within 48h of death\n",
    "* IF no death date/time available: at time of last recorded vital signs\n",
    "* No contraindications\n",
    "* CLIF Microbiology_culture:\n",
    "    * No positive blood cultures within 2 days - 'no_positive_culture_48hrs'\n",
    "* Hospital diagnosis (ICD based) -- 'icd10_contraindication',\n",
    "    * Cancer\n",
    "    * Severe sepsis\n",
    "* Pass the potential organ quality assessment check (independent assessment) using last recorded lab values, as defined by CMS:- organ_check_pass\n",
    "    * Kidney: recorded creatinine, Cr < 4 AND not on CRRT\n",
    "    * Liver: recorded TB, AST, ALT and\n",
    "        * Total bilirubin < 4\n",
    "        * AST < 700\n",
    "        * ALT < 700\n",
    "    * BMI <= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24fd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Create CLIF-eligible-donors flag\n",
    "# ============================================\n",
    "\n",
    "\n",
    "final_cohort_df = final_cohort_df.with_columns([\n",
    "    # Overall CLIF-eligible-donors flag\n",
    "    (\n",
    "        # 2. Age < 75\n",
    "        (pl.col('age_75_less')) &\n",
    "        # 3. On invasive mechanical ventilation (within 48h of death)\n",
    "        (pl.col('imv_48hr_expire')) &\n",
    "        # 4. No contraindications (no cancer, no severe sepsis)\n",
    "        (~pl.col('icd10_contraindication')) &\n",
    "        # 5. No positive blood cultures within 48h\n",
    "        (pl.col('no_positive_culture_48hrs')) &\n",
    "        # 6. Pass organ quality assessment (kidney OR liver AND BMI)\n",
    "        (pl.col('organ_check_pass'))\n",
    "    ).alias('clif_eligible_donors')\n",
    "])\n",
    "\n",
    "# Count for STROBE tracking\n",
    "clif_eligible_n = final_cohort_df.filter(pl.col('clif_eligible_donors'))['patient_id'].n_unique()\n",
    "strobe_counts[\"clif_eligible_donors\"] = clif_eligible_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d8e3c",
   "metadata": {},
   "source": [
    "# Patient assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9778089",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_assessments_filepath = f\"{tables_path}/clif_patient_assessments.{file_type}\"\n",
    "patient_assessments_df = read_data(\n",
    "      patient_assessments_filepath,\n",
    "      file_type,\n",
    "      filter_ids=all_decedent_inpatient_hosp_ids,\n",
    "      id_column='hospitalization_id'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be95492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient assessments - use DuckDB to avoid crashes\n",
    "print(\"Processing patient assessments with DuckDB...\")\n",
    "\n",
    "final_cohort_for_assessments = final_cohort_df.select([\n",
    "    \"hospitalization_id\", \"final_death_dttm\"\n",
    "]).to_pandas()\n",
    "\n",
    "assessments_query = f\"\"\"\n",
    "WITH assessments_filtered AS (\n",
    "    SELECT \n",
    "        hospitalization_id,\n",
    "        recorded_dttm,\n",
    "        LOWER(assessment_category) AS assessment_category,\n",
    "        numerical_value\n",
    "    FROM read_parquet('{tables_path}/clif_patient_assessments.{file_type}')\n",
    "    WHERE LOWER(assessment_category) IN ('gcs_total', 'rass')\n",
    "        AND numerical_value IS NOT NULL\n",
    "        AND hospitalization_id IN (SELECT hospitalization_id FROM final_cohort_for_assessments)\n",
    "),\n",
    "with_death_time AS (\n",
    "    SELECT \n",
    "        a.hospitalization_id,\n",
    "        a.recorded_dttm,\n",
    "        a.assessment_category,\n",
    "        a.numerical_value,\n",
    "        f.final_death_dttm,\n",
    "        ABS(EXTRACT(EPOCH FROM (f.final_death_dttm - a.recorded_dttm))) AS abs_time_to_death\n",
    "    FROM assessments_filtered a\n",
    "    INNER JOIN final_cohort_for_assessments f ON a.hospitalization_id = f.hospitalization_id\n",
    "),\n",
    "closest_per_category AS (\n",
    "    SELECT \n",
    "        hospitalization_id,\n",
    "        assessment_category,\n",
    "        numerical_value,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY hospitalization_id, assessment_category \n",
    "            ORDER BY abs_time_to_death\n",
    "        ) AS rn\n",
    "    FROM with_death_time\n",
    ")\n",
    "SELECT \n",
    "    hospitalization_id,\n",
    "    MAX(CASE WHEN assessment_category = 'gcs_total' THEN numerical_value END) AS gcs_total_value,\n",
    "    MAX(CASE WHEN assessment_category = 'rass' THEN numerical_value END) AS rass_value\n",
    "FROM closest_per_category\n",
    "WHERE rn = 1\n",
    "GROUP BY hospitalization_id\n",
    "\"\"\"\n",
    "\n",
    "patient_gcs_rass_pd = duckdb.sql(assessments_query).df()\n",
    "patient_gcs_rass = pl.from_pandas(patient_gcs_rass_pd)\n",
    "\n",
    "print(f\"✓ Processed assessments for {len(patient_gcs_rass)} hospitalizations\")\n",
    "\n",
    "# Join to final_cohort_df\n",
    "final_cohort_df = final_cohort_df.join(\n",
    "    patient_gcs_rass,\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(\"✓ Patient assessments processing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# ENSURE PATIENT-LEVEL ANALYSIS\n",
    "# ================================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINALIZING PATIENT-LEVEL COHORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: First, remove encounter-level identifiers\n",
    "print(\"Step 1: Removing encounter-level identifiers (hospitalization_id, encounter_block)...\")\n",
    "columns_to_drop = []\n",
    "if 'hospitalization_id' in final_cohort_df.columns:\n",
    "    columns_to_drop.append('hospitalization_id')\n",
    "if 'encounter_block' in final_cohort_df.columns:\n",
    "    columns_to_drop.append('encounter_block')\n",
    "\n",
    "if columns_to_drop:\n",
    "    final_cohort_df = final_cohort_df.drop(columns_to_drop)\n",
    "    print(f\"✓ Dropped: {', '.join(columns_to_drop)}\")\n",
    "else:\n",
    "    print(\"✓ No encounter-level identifiers found to drop\")\n",
    "\n",
    "# Step 2: Now deduplicate to ensure one row per patient\n",
    "print(\"\\nStep 2: Ensuring one row per patient...\")\n",
    "n_patients_before = final_cohort_df['patient_id'].n_unique()\n",
    "n_rows_before = len(final_cohort_df)\n",
    "\n",
    "if n_patients_before != n_rows_before:\n",
    "    print(f\"WARNING: {n_rows_before:,} rows but only {n_patients_before:,} unique patients!\")\n",
    "    print(\"Deduplicating to ensure one row per patient...\")\n",
    "\n",
    "    # Deduplicate keeping the last entry per patient (most recent data)\n",
    "    final_cohort_df = final_cohort_df.unique(subset=['patient_id'], keep='last')\n",
    "\n",
    "    n_rows_after = len(final_cohort_df)\n",
    "    print(f\"✓ Deduplicated: {n_rows_before:,} rows → {n_rows_after:,} rows\")\n",
    "    print(f\"Removed {n_rows_before - n_rows_after:,} duplicate rows\")\n",
    "else:\n",
    "    print(f\"✓ Already unique: {n_patients_before:,} patients = {n_rows_before:,} rows\")\n",
    "\n",
    "# Step 3: Final verification\n",
    "n_patients_final = final_cohort_df['patient_id'].n_unique()\n",
    "n_rows_final = len(final_cohort_df)\n",
    "assert n_patients_final == n_rows_final, \\\n",
    "    f\"CRITICAL: Still have duplicates! {n_rows_final} rows but {n_patients_final} unique patients\"\n",
    "\n",
    "print(f\"\\n✓ Final verification passed: {n_patients_final:,} unique patients\")\n",
    "print(f\"Final cohort shape: {final_cohort_df.shape}\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217bccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cohort_df.write_parquet(str(OUTPUT_INTERMEDIATE_DIR / \"final_cohort_df.parquet\"))\n",
    "pd.DataFrame([strobe_counts]).to_csv(str(OUTPUT_FINAL_DIR / \"strobe_counts.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552b321",
   "metadata": {},
   "source": [
    "# Table One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556cb95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.table_one import create_table_one\n",
    "table_one = create_table_one(final_cohort_df, output_dir=str(OUTPUT_FINAL_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17afd60a",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceef363",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9076d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.cohort_visualizations import create_all_visualizations\n",
    "summary_df = create_all_visualizations(final_cohort_df, output_dir=str(OUTPUT_FINAL_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af4dd9",
   "metadata": {},
   "source": [
    "# STROBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.strobe_diagram import create_strobe_diagrams_for_cohorts\n",
    "results = create_strobe_diagrams_for_cohorts(\n",
    "      final_cohort_df,\n",
    "      output_dir=str(OUTPUT_FINAL_DIR),\n",
    "      save_figures=True,\n",
    "      save_csvs=True\n",
    "  )\n",
    "\n",
    "# Access results\n",
    "calc_stages = results['CALC']['stages']\n",
    "clif_stages = results['CLIF']['stages']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
